{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de Remuestreo K-fold Cross Validation\n",
    "\n",
    "El método de K-fold cross validation permite ajustar repetidamente un modelo en diferentes partes del conjunto de entrenamiento y probar su rendimiento en otras partes del mismo conjunto.\n",
    "#### K-fold Cross Validation\n",
    "Es el remuestreo estándar de la industria para estudiar el rendimiento futuro del modelo.\n",
    "\n",
    "**Pasos del K-fold Cross Validation**:\n",
    "\n",
    "1. **División de los Datos**:\n",
    "   - Divide aleatoriamente los datos de entrenamiento en \\( K \\) grupos del mismo tamaño (aproximadamente).\n",
    "   \n",
    "2. **Ajuste del Modelo**:\n",
    "   - Ajusta el modelo utilizando \\( K-1 \\) grupos, es decir, todos menos uno. El grupo restante (grupo de validación) se utiliza para calcular el rendimiento del modelo.\n",
    "   \n",
    "3. **Rotación del Conjunto de Validación**:\n",
    "   - En las siguientes repeticiones, un grupo diferente se trata como conjunto de validación. Esto significa que cada grupo se utilizará una vez como conjunto de validación.\n",
    "   \n",
    "4. **Cálculo del Error de Generalización**:\n",
    "   - Promedia las (k) estimaciones del error de generalización (e_1, e_2, e_3, ... e_k ), que es la diferencia entre el valor predicho y el observado.\n",
    "   - Este método proporciona una aproximación del error para los datos no observados.\n",
    "\n",
    "\n",
    "- En general, se dice que con \\( K > 10 \\), se alcanzan resultados similares al caso extremo en que el número de folds es igual al número de observaciones en los datos (\\( K=n \\)), llamado leave-one-out CV (LOOCV).\n",
    "\n",
    "- Es útil realizar el procedimiento de K-fold cross validation repetidamente, es decir, varios K-fold cross validations, para que la distribución de los valores de la variable objetivo en los folds sea lo más representativa posible de la data original. Este método ayuda a aumentar la precisión del error de generalización estimado.\n",
    "\n",
    "- Aunque un \\( K \\) mayor o igual a 10 minimiza la variabilidad del rendimiento estimado, K-fold CV tiende a tener una mayor variabilidad que el bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de Remuestreo: Bootstrapping\n",
    "\n",
    "### Muestra Aleatoria con Reemplazo\n",
    "En bootstrapping, se toman múltiples muestras aleatorias con reemplazo del conjunto de datos de entrenamiento. Esto significa que cada muestra (bootstrap sample) puede tener filas repetidas y algunas filas pueden no estar presentes. Cada muestra tiene el mismo tamaño que el conjunto de datos original.\n",
    "\n",
    "### Filas Out-of-Bag (OOB)\n",
    "Las observaciones que no se incluyen en una muestra particular se denominan filas out-of-bag (OOB). Estas filas se utilizan para evaluar el rendimiento del modelo. **(conjunto de validación)**\n",
    "\n",
    "### Proceso de Bootstrapping\n",
    "El proceso de bootstrapping para evaluar el rendimiento de un modelo incluye los siguientes pasos:\n",
    "\n",
    "1. **Generación de Muestras de Bootstrap**: Se generan múltiples muestras de bootstrap a partir del conjunto de datos de entrenamiento.\n",
    "2. **Entrenamiento del Modelo**: Para cada muestra de bootstrap, se entrena un modelo.\n",
    "3. **Evaluación con Filas OOB**: Se evalúa el rendimiento del modelo utilizando las filas OOB correspondientes a esa muestra de bootstrap. **(conjunto de validación)**\n",
    "4. **Promedio de Evaluaciones**: Se repite el proceso múltiples veces y se promedian las evaluaciones para obtener una estimación del rendimiento del modelo.\n",
    "\n",
    "\n",
    "**División Inicial de Datos**: Se divide el conjunto de datos original en conjunto de entrenamiento y conjunto de prueba mediante muestreo aleatorio simple o estratificado.\n",
    "\n",
    "**Generación de Muestras de Bootstrap**:\n",
    "- Supongamos que el conjunto de entrenamiento tiene 8000 filas.\n",
    "- Se genera la primera muestra de bootstrap tomando 8000 filas aleatorias con reemplazo del conjunto de entrenamiento. Algunas filas pueden repetirse y otras pueden faltar (OOB).\n",
    "- Se repite este proceso para generar múltiples muestras de bootstrap (e.g., 1000 muestras).\n",
    "\n",
    "**Entrenamiento del Modelo**:\n",
    "- Para cada muestra de bootstrap, se entrena un modelo usando solo las filas dentro de esa muestra.\n",
    "\n",
    "**Evaluación con Filas OOB**:\n",
    "- Para cada modelo entrenado, se utiliza el conjunto de filas OOB para evaluar el rendimiento del modelo.\n",
    "- Dado que las filas OOB no se utilizaron para entrenar el modelo, proporcionan una estimación independiente del rendimiento del modelo, similar a cómo funcionan los conjuntos de validación en el método k-fold CV.\n",
    "- Se calculan métricas de rendimiento (e.g., error cuadrático medio, precisión, recall) comparando las predicciones del modelo con los valores observados en las filas OOB.\n",
    "\n",
    "**Promedio de Evaluaciones**:\n",
    "- Se repite el proceso de entrenamiento y evaluación para todas las muestras de bootstrap.\n",
    "- Se promedian las métricas de rendimiento obtenidas de todas las evaluaciones con filas OOB para obtener una estimación final del rendimiento del modelo.\n",
    "\n",
    "### Consideraciones\n",
    "- **Tamaño del Conjunto de Datos**: Bootstrapping puede ser problemático en conjuntos de datos más pequeños porque las filas repetidas y faltantes son más relevantes, lo que puede inducir a errores mayores de predicción.\n",
    "\n",
    "### Detalle sobre Variabilidad y Sesgo en Bootstrapping y K-fold Cross-Validation\n",
    "\n",
    "**Contexto y Definiciones**:\n",
    "- **Variabilidad**: Se refiere a cuánto varían las estimaciones del modelo cuando se entrenan en diferentes subconjuntos de datos. Alta variabilidad significa que las predicciones del modelo pueden cambiar considerablemente con diferentes muestras de datos.\n",
    "- **Sesgo**: Es el error sistemático introducido por un modelo que no puede captar la complejidad de los datos. Un alto sesgo significa que el modelo hace suposiciones simplistas y no se ajusta bien a los datos.\n",
    "\n",
    "**Explicación del Bootstrapping**:\n",
    "- **Muestra Aleatoria con Reemplazo**:\n",
    "  - En bootstrapping, se generan múltiples muestras de bootstrap del conjunto de datos de entrenamiento original.\n",
    "  - Cada muestra de bootstrap se selecciona con reemplazo, lo que significa que algunas filas pueden aparecer múltiples veces en la misma muestra, mientras que otras filas pueden no aparecer en absoluto.\n",
    "- **Menor Variabilidad**:\n",
    "  - Debido a que cada muestra de bootstrap es una variación del conjunto de datos de entrenamiento original con algunas filas duplicadas, las muestras tienden a ser menos diversas comparadas con los folds en k-fold CV.\n",
    "  - Esto significa que las muestras de bootstrap pueden ser más similares entre sí, lo que lleva a una menor variabilidad en las estimaciones del modelo. En otras palabras, los modelos entrenados en diferentes muestras de bootstrap tienden a producir predicciones más consistentes.\n",
    "- **Mayor Sesgo**:\n",
    "  - La duplicación de filas y la ausencia de algunas filas en cada muestra de bootstrap pueden introducir un sesgo en la medida del error.\n",
    "  - Esto ocurre porque las muestras de bootstrap no son completamente representativas del conjunto de datos original debido a la repetición de algunas filas y la exclusión de otras. Como resultado, el modelo puede estar ajustado a un subconjunto menos diverso de datos, lo que lleva a un mayor sesgo en las estimaciones del error.\n",
    "\n",
    "**Comparación con k-fold Cross-Validation**:\n",
    "- **Muestra Aleatoria sin Reemplazo**:\n",
    "  - En k-fold CV, el conjunto de datos de entrenamiento se divide en \\( k \\) partes (folds o carpetas) de manera que cada fold es aproximadamente del mismo tamaño y las divisiones no se superponen.\n",
    "  - Cada fold se utiliza una vez como conjunto de validación, mientras que los \\( k-1 \\) folds restantes se utilizan como conjunto de entrenamiento.\n",
    "- **Mayor Variabilidad**:\n",
    "  - Debido a que cada fold de validación en k-fold CV es único y no contiene duplicados, las diferentes combinaciones de datos de entrenamiento y validación tienden a ser más diversas.\n",
    "  - Esto introduce una mayor variabilidad en las estimaciones del modelo, ya que cada fold proporciona una vista diferente de los datos. Los modelos entrenados en diferentes combinaciones de folds pueden producir predicciones más variadas.\n",
    "- **Menor Sesgo**:\n",
    "  - La ausencia de duplicación y la inclusión de todas las filas en algún punto del proceso de validación en k-fold CV hacen que las estimaciones del modelo sean menos sesgadas.\n",
    "  - Cada fold de validación es una representación más fiel del conjunto de datos original. Esto reduce el sesgo en las estimaciones del error, proporcionando una medida más precisa del rendimiento del modelo.\n",
    "\n",
    "**Ejemplo Ilustrativo**:\n",
    "Imaginemos un conjunto de datos con 10 observaciones: A, B, C, D, E, F, G, H, I, J.\n",
    "\n",
    "- **Bootstrapping**:\n",
    "  - Muestra de Bootstrap 1: A, B, B, D, E, F, F, H, I, J (observaciones B y F repetidas; C y G faltantes).\n",
    "  - Muestra de Bootstrap 2: A, A, C, D, E, G, H, I, I, J (observaciones A e I repetidas; B y F faltantes).\n",
    "\n",
    "- **k-fold Cross-Validation (k=5)**:\n",
    "  - Fold 1: (A, B) (entrenamiento); (C, D, E, F, G, H, I, J) (validación).\n",
    "  - Fold 2: (C, D) (entrenamiento); (A, B, E, F, G, H, I, J) (validación).\n",
    "\n",
    "En bootstrapping, algunas observaciones están repetidas y otras faltan, lo que reduce la diversidad entre las muestras y aumenta el sesgo. En k-fold CV, cada fold es una representación más única y completa del conjunto de datos, lo que aumenta la variabilidad y reduce el sesgo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método de Remuestreo Jackknife\n",
    "\n",
    "El método de remuestreo Jackknife es una técnica estadística utilizada para estimar la variabilidad de un estimador, como la media o la varianza. Este método es particularmente útil para evaluar el sesgo y la varianza de los estimadores en muestras pequeñas. A continuación, se detalla el método, se proporciona un ejemplo, se discuten sus pros y contras, se explica la matemática/estadística subyacente y se compara con los métodos de K-fold Cross Validation y Bootstrapping.\n",
    "\n",
    "### Proceso del Método Jackknife\n",
    "\n",
    "El método Jackknife se basa en la eliminación sistemática de una observación a la vez del conjunto de datos y en el cálculo del estimador en cada subconjunto de datos resultante. Los pasos generales son los siguientes:\n",
    "\n",
    "### División Inicial\n",
    "\n",
    "Supongamos que tenemos un conjunto de datos con $n$ observaciones.\n",
    "\n",
    "### Generación de Submuestras\n",
    "\n",
    "Se crean $n$ submuestras, cada una de las cuales contiene $n-1$ observaciones. Cada submuestra se forma eliminando una observación diferente del conjunto de datos original.\n",
    "\n",
    "### Cálculo del Estimador\n",
    "\n",
    "Para cada submuestra, se calcula el estimador de interés (e.g., media, varianza).\n",
    "\n",
    "### Cálculo del Estimador Jackknife\n",
    "\n",
    "Se promedian los estimadores calculados para obtener una estimación del sesgo y la varianza del estimador original.\n",
    "\n",
    "### Ejemplo de Aplicación del Método Jackknife\n",
    "\n",
    "Supongamos que tenemos un conjunto de datos con 5 observaciones: [10, 20, 30, 40, 50].\n",
    "\n",
    "### Paso 1: Generación de Submuestras\n",
    "\n",
    "- Submuestra 1: [20, 30, 40, 50] (eliminamos la primera observación)\n",
    "- Submuestra 2: [10, 30, 40, 50] (eliminamos la segunda observación)\n",
    "- Submuestra 3: [10, 20, 40, 50] (eliminamos la tercera observación)\n",
    "- Submuestra 4: [10, 20, 30, 50] (eliminamos la cuarta observación)\n",
    "- Submuestra 5: [10, 20, 30, 40] (eliminamos la quinta observación)\n",
    "\n",
    "### Paso 2: Cálculo del Estimador (Media)\n",
    "\n",
    "- Media de la submuestra 1: $\\frac{20 + 30 + 40 + 50}{4} = 35$\n",
    "- Media de la submuestra 2: $\\frac{10 + 30 + 40 + 50}{4} = 32.5$\n",
    "- Media de la submuestra 3: $\\frac{10 + 20 + 40 + 50}{4} = 30$\n",
    "- Media de la submuestra 4: $\\frac{10 + 20 + 30 + 50}{4} = 27.5$\n",
    "- Media de la submuestra 5: $\\frac{10 + 20 + 30 + 40}{4} = 25$\n",
    "\n",
    "### Paso 3: Cálculo del Estimador Jackknife\n",
    "\n",
    "- Media de todas las medias: $\\frac{35 + 32.5 + 30 + 27.5 + 25}{5} = 30$\n",
    "\n",
    "Varianza Jackknife:\n",
    "$$\n",
    "Var(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^{n} (\\hat{\\theta}_i - \\bar{\\theta})^2\n",
    "$$\n",
    "donde $\\hat{\\theta}_i$ es la media de cada submuestra y $\\bar{\\theta}$ es la media de todas las medias.\n",
    "\n",
    "### Pros y Contras del Método Jackknife\n",
    "\n",
    "### Pros:\n",
    "\n",
    "- **Simplicidad**: Fácil de implementar y entender.\n",
    "- **Sesgo Reducido**: Ofrece una buena estimación del sesgo del estimador.\n",
    "- **Eficiencia Computacional**: Menos intensivo computacionalmente en comparación con el bootstrapping.\n",
    "\n",
    "### Contras:\n",
    "\n",
    "- **Subestimación de la Varianza**: Puede subestimar la varianza del estimador en muestras pequeñas.\n",
    "- **Sensibilidad a Outliers**: Es sensible a la presencia de outliers en el conjunto de datos.\n",
    "\n",
    "### Matemática/Estadística Subyacente\n",
    "\n",
    "El método Jackknife se basa en la idea de eliminar una observación a la vez y calcular el estimador de interés en cada subconjunto resultante. La fórmula de la varianza Jackknife es:\n",
    "\n",
    "$$\n",
    "Var(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^{n} (\\hat{\\theta}_i - \\bar{\\theta})^2\n",
    "$$\n",
    "\n",
    "donde $n$ es el número total de observaciones, $\\hat{\\theta}_i$ es el estimador calculado en la $i$-ésima submuestra, y $\\bar{\\theta}$ es la media de todos los $\\hat{\\theta}_i$.\n",
    "\n",
    "### Comparación de Jackknife con K-fold Cross Validation y Bootstrapping\n",
    "\n",
    "### Jackknife vs. K-fold Cross Validation:\n",
    "\n",
    "- **Enfoque**: Jackknife elimina una observación a la vez, mientras que K-fold CV divide los datos en $k$ grupos.\n",
    "- **Variabilidad**: K-fold CV puede proporcionar una mejor estimación de la variabilidad del modelo, ya que utiliza múltiples divisiones.\n",
    "- **Uso**: K-fold CV es más adecuado para evaluar el rendimiento predictivo de los modelos de machine learning, mientras que Jackknife se utiliza más para estimar el sesgo y la varianza de los estimadores.\n",
    "\n",
    "### Jackknife vs. Bootstrapping:\n",
    "\n",
    "- **Enfoque**: Bootstrapping genera múltiples muestras con reemplazo, mientras que Jackknife elimina una observación a la vez.\n",
    "- **Variabilidad y Sesgo**: Bootstrapping tiende a proporcionar una mejor estimación de la variabilidad del modelo, mientras que Jackknife es más sencillo y menos intensivo computacionalmente.\n",
    "- **Precisión**: Bootstrapping generalmente proporciona estimaciones más precisas de la varianza y el sesgo, especialmente en muestras pequeñas.\n",
    "\n",
    "\n",
    "El método Jackknife es una técnica de remuestreo útil para estimar la variabilidad y el sesgo de un estimador, especialmente en conjuntos de datos más pequeños. Aunque tiene algunas limitaciones, su simplicidad y eficiencia computacional lo hacen una herramienta valiosa en el análisis estadístico. Comparado con K-fold Cross Validation y Bootstrapping, el Jackknife es menos intensivo computacionalmente pero puede subestimar la varianza en muestras pequeñas y es más sensible a outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativa Detallada entre K-fold Cross Validation, Bootstrapping y Jackknife\n",
    "\n",
    "\n",
    "En el contexto de machine learning, los métodos de remuestreo son fundamentales para entrenar los modelos. Tres de estos metodos son K-fold Cross Validation, Bootstrapping y Jackknife. A continuación, se presenta una comparativa detallada de estos métodos, considerando aspectos como varianza, sesgo, precisión, eficiencia computacional, iteraciones, muestras, filas u observaciones del conjunto de validación y conjunto de entrenamiento.\n",
    "\n",
    "### K-fold Cross Validation\n",
    "\n",
    "### Descripción\n",
    "\n",
    "K-fold Cross Validation (CV) divide el conjunto de datos en $k$ grupos (folds) de tamaño aproximadamente igual. El proceso implica entrenar el modelo $k$ veces, cada vez utilizando $k-1$ folds para entrenamiento y el fold restante para validación.\n",
    "\n",
    "### Parámetros\n",
    "\n",
    "- **Número de folds (k)**: Típicamente se usa $k = 5$ o $k = 10$.\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "- **Varianza**: Proporciona una buena estimación de la variabilidad del modelo ya que utiliza múltiples divisiones.\n",
    "- **Sesgo**: Tiende a tener un sesgo bajo debido al uso de múltiples folds.\n",
    "- **Precisión**: Ofrece una estimación precisa del rendimiento del modelo.\n",
    "- **Simplicidad**: Relativamente fácil de implementar y entender.\n",
    "- **Conjunto de Entrenamiento y Validación**: Utiliza $\\frac{k-1}{k}$ del conjunto de datos para entrenamiento y $\\frac{1}{k}$ para validación en cada iteración.\n",
    "\n",
    "### Desventajas\n",
    "\n",
    "- **Eficiencia Computacional**: Más intensivo computacionalmente que el Jackknife debido a las múltiples iteraciones.\n",
    "- **Iteraciones**: Requiere $k$ iteraciones, lo que puede ser costoso para valores grandes de $k$.\n",
    "\n",
    "### Bootstrapping\n",
    "\n",
    "### Descripción\n",
    "\n",
    "Bootstrapping genera múltiples muestras con reemplazo del conjunto de datos original. Cada muestra de bootstrap se utiliza para entrenar el modelo y las observaciones no incluidas (out-of-bag) se utilizan para la validación.\n",
    "\n",
    "### Parámetros\n",
    "\n",
    "- **Número de muestras (n\\_bootstraps)**: Número de muestras bootstrap generadas, comúnmente 1000.\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "- **Varianza**: Proporciona una excelente estimación de la variabilidad del modelo, especialmente en muestras pequeñas.\n",
    "- **Sesgo**: Puede proporcionar una buena estimación del sesgo del modelo.\n",
    "- **Precisión**: Generalmente ofrece estimaciones más precisas de la varianza y el sesgo.\n",
    "- **Simplicidad**: Sencillo de implementar y entender.\n",
    "\n",
    "### Desventajas\n",
    "\n",
    "- **Eficiencia Computacional**: Muy intensivo computacionalmente debido a la generación de múltiples muestras y el entrenamiento repetido.\n",
    "- **Iteraciones**: Requiere un gran número de iteraciones, lo que aumenta el costo computacional.\n",
    "- **Conjunto de Entrenamiento y Validación**: Cada muestra contiene $n$ observaciones con reemplazo y las filas out-of-bag se utilizan para validación.\n",
    "\n",
    "### Jackknife\n",
    "\n",
    "### Descripción\n",
    "\n",
    "El método Jackknife elimina sistemáticamente una observación a la vez del conjunto de datos y calcula el estimador en cada subconjunto resultante.\n",
    "\n",
    "### Parámetros\n",
    "\n",
    "- **Número de submuestras**: Igual al número de observaciones ($n$).\n",
    "\n",
    "### Ventajas\n",
    "\n",
    "- **Varianza**: Puede subestimar la varianza del estimador en muestras pequeñas.\n",
    "- **Sesgo**: Ofrece una buena estimación del sesgo del estimador.\n",
    "- **Precisión**: Menos preciso en estimar la varianza comparado con bootstrapping.\n",
    "- **Simplicidad**: Muy fácil de implementar y entender.\n",
    "- **Eficiencia Computacional**: Menos intensivo computacionalmente comparado con bootstrapping y, en algunos casos, K-fold CV.\n",
    "\n",
    "### Desventajas\n",
    "\n",
    "- **Varianza**: Subestima la varianza en muestras pequeñas.\n",
    "- **Sensibilidad a Outliers**: Sensible a la presencia de outliers.\n",
    "- **Iteraciones**: Realiza $n$ iteraciones, lo que puede ser costoso en conjuntos de datos grandes.\n",
    "- **Conjunto de Entrenamiento y Validación**: Cada iteración entrena con $n-1$ observaciones y valida con 1 observación.\n",
    "\n",
    "### Comparativa\n",
    "\n",
    "### Varianza\n",
    "\n",
    "- **K-fold CV**: Proporciona una buena estimación de la variabilidad debido a las múltiples divisiones.\n",
    "- **Bootstrapping**: Excelente estimación de la variabilidad, especialmente en muestras pequeñas.\n",
    "- **Jackknife**: Puede subestimar la variabilidad en muestras pequeñas.\n",
    "\n",
    "### Sesgo\n",
    "\n",
    "- **K-fold CV**: Sesgo bajo debido al uso de múltiples folds.\n",
    "- **Bootstrapping**: Proporciona una buena estimación del sesgo.\n",
    "- **Jackknife**: Ofrece una buena estimación del sesgo.\n",
    "\n",
    "### Precisión\n",
    "\n",
    "- **K-fold CV**: Estimación precisa del rendimiento del modelo.\n",
    "- **Bootstrapping**: Ofrece estimaciones más precisas de la varianza y el sesgo.\n",
    "- **Jackknife**: Menos preciso en estimar la varianza comparado con bootstrapping.\n",
    "\n",
    "### Simplicidad\n",
    "\n",
    "- **K-fold CV**: Relativamente fácil de implementar y entender.\n",
    "- **Bootstrapping**: Sencillo de implementar y entender.\n",
    "- **Jackknife**: Muy fácil de implementar y entender.\n",
    "\n",
    "### Eficiencia Computacional\n",
    "\n",
    "- **K-fold CV**: Más intensivo computacionalmente que Jackknife.\n",
    "- **Bootstrapping**: Muy intensivo computacionalmente.\n",
    "- **Jackknife**: Menos intensivo computacionalmente comparado con bootstrapping y, en algunos casos, K-fold CV.\n",
    "\n",
    "### Iteraciones\n",
    "\n",
    "- **K-fold CV**: Requiere $k$ iteraciones.\n",
    "- **Bootstrapping**: Requiere un gran número de iteraciones ($n_{\\text{bootstraps}}$).\n",
    "- **Jackknife**: Realiza $n$ iteraciones.\n",
    "\n",
    "### Conjunto de Entrenamiento y Validación\n",
    "\n",
    "- **K-fold CV**: Utiliza $\\frac{k-1}{k}$ del conjunto de datos para entrenamiento y $\\frac{1}{k}$ para validación en cada iteración.\n",
    "- **Bootstrapping**: Cada muestra contiene $n$ observaciones con reemplazo y las filas out-of-bag se utilizan para validación.\n",
    "- **Jackknife**: Cada iteración entrena con $n-1$ observaciones y valida con 1 observación.\n",
    "\n",
    "### Conclusiones respecto a la comparativa\n",
    "\n",
    "Cada método de remuestreo tiene sus propias ventajas y desventajas, y la elección del método adecuado depende del contexto y de los objetivos específicos del análisis. K-fold Cross Validation es generalmente preferido para evaluar el rendimiento predictivo de los modelos de machine learning debido a su equilibrio entre varianza y sesgo. Bootstrapping es ideal para estimaciones precisas de la varianza y el sesgo, especialmente en muestras pequeñas, aunque es más intensivo computacionalmente. Jackknife, por otro lado, es muy fácil de implementar y es menos intensivo computacionalmente, pero puede subestimar la varianza en muestras pequeñas y es sensible a los outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objetivos y Alcances\n",
    "\n",
    "#### Objetivos\n",
    "\n",
    "1. Implementar el método de remuestreo Jackknife para evaluar el rendimiento de un modelo de regresión lineal.\n",
    "2. Comprobar la variabilidad, el sesgo y la varianza del estimador utilizando el dataset de gasto en publicidad y ventas.\n",
    "3. Comparar el método Jackknife con otros métodos de remuestreo como K-fold Cross Validation y Bootstrapping.\n",
    "4. Analizar la subestimación de la varianza en muestras pequeñas y comparar la eficiencia computacional de los métodos.\n",
    "5. Evaluar y comparar las métricas de rendimiento y su precisión entre los métodos de remuestreo.\n",
    "\n",
    "#### Alcances\n",
    "\n",
    "1. Cargar y explorar el dataset de gasto en publicidad y ventas.\n",
    "2. Dividir los datos en conjunto de entrenamiento y prueba.\n",
    "3. Aplicar el método Jackknife para estimar la variabilidad, el sesgo y la varianza del modelo de regresión lineal.\n",
    "4. Evaluar el modelo utilizando métricas como RMSE, MAE, correlación y r^2\n",
    "5. Comparar los resultados obtenidos con los métodos K-fold Cross Validation y Bootstrapping.\n",
    "6. Analizar la eficiencia computacional de cada método de remuestreo.\n",
    "7. Explicar y demostrar el proceso paso a paso, incluyendo el cálculo de métricas de rendimiento, variabilidad y tiempo de ejecución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de Datos Utilizada: Advertising Sales Dataset\n",
    "https://www.kaggle.com/datasets/yasserh/advertising-sales-dataset/\n",
    "\n",
    "En la página del dataset se informa claramente que los valores de las columnas de tv ad budget, radio ad budget y Newspaper ad budget estan en escala de miles de dolares, y que a su vez los valores de la columna sales, estan en escala de millones de dolares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo las librerias necesarias para trabajar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Librerías necesarias\n",
    "library(dplyr)\n",
    "library(readr)\n",
    "library(ggplot2)\n",
    "library(caret)\n",
    "library(rsample)\n",
    "#Para medir el tiempo de ejecución\n",
    "library(microbenchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargo el dataset de gasto en publicidad y ventas, para verificar su contenido inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>X</th><th scope=col>TV.Ad.Budget....</th><th scope=col>Radio.Ad.Budget....</th><th scope=col>Newspaper.Ad.Budget....</th><th scope=col>Sales....</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>230.1</td><td>37.8</td><td>69.2</td><td>22.1</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td> 44.5</td><td>39.3</td><td>45.1</td><td>10.4</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>3</td><td> 17.2</td><td>45.9</td><td>69.3</td><td> 9.3</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>4</td><td>151.5</td><td>41.3</td><td>58.5</td><td>18.5</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>5</td><td>180.8</td><td>10.8</td><td>58.4</td><td>12.9</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>6</td><td>  8.7</td><td>48.9</td><td>75.0</td><td> 7.2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & X & TV.Ad.Budget.... & Radio.Ad.Budget.... & Newspaper.Ad.Budget.... & Sales....\\\\\n",
       "  & <int> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & 230.1 & 37.8 & 69.2 & 22.1\\\\\n",
       "\t2 & 2 &  44.5 & 39.3 & 45.1 & 10.4\\\\\n",
       "\t3 & 3 &  17.2 & 45.9 & 69.3 &  9.3\\\\\n",
       "\t4 & 4 & 151.5 & 41.3 & 58.5 & 18.5\\\\\n",
       "\t5 & 5 & 180.8 & 10.8 & 58.4 & 12.9\\\\\n",
       "\t6 & 6 &   8.7 & 48.9 & 75.0 &  7.2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 5\n",
       "\n",
       "| <!--/--> | X &lt;int&gt; | TV.Ad.Budget.... &lt;dbl&gt; | Radio.Ad.Budget.... &lt;dbl&gt; | Newspaper.Ad.Budget.... &lt;dbl&gt; | Sales.... &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 1 | 1 | 230.1 | 37.8 | 69.2 | 22.1 |\n",
       "| 2 | 2 |  44.5 | 39.3 | 45.1 | 10.4 |\n",
       "| 3 | 3 |  17.2 | 45.9 | 69.3 |  9.3 |\n",
       "| 4 | 4 | 151.5 | 41.3 | 58.5 | 18.5 |\n",
       "| 5 | 5 | 180.8 | 10.8 | 58.4 | 12.9 |\n",
       "| 6 | 6 |   8.7 | 48.9 | 75.0 |  7.2 |\n",
       "\n"
      ],
      "text/plain": [
       "  X TV.Ad.Budget.... Radio.Ad.Budget.... Newspaper.Ad.Budget.... Sales....\n",
       "1 1 230.1            37.8                69.2                    22.1     \n",
       "2 2  44.5            39.3                45.1                    10.4     \n",
       "3 3  17.2            45.9                69.3                     9.3     \n",
       "4 4 151.5            41.3                58.5                    18.5     \n",
       "5 5 180.8            10.8                58.4                    12.9     \n",
       "6 6   8.7            48.9                75.0                     7.2     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "base_publicidad <- read.csv(\"Advertising Budget and Sales.csv\")\n",
    "# Ver los primeros registros del dataset\n",
    "head(base_publicidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Esta base de datos contiene datos sobre los presupuestos de publicidad en TV, radio y periódicos, y las correspondientes ventas.\n",
    "- Con `head` obtengo una vista previa rápida de la estructura de los datos y verifico que la carga se realizó correctamente.\n",
    "- Sin embargo observo que existe una columna llamada \"X\" que no aporta ninguna información, y que es solo la enumeración de las observaciones, por lo que proceso a eliminarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>TV.Ad.Budget....</th><th scope=col>Radio.Ad.Budget....</th><th scope=col>Newspaper.Ad.Budget....</th><th scope=col>Sales....</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>230.1</td><td>37.8</td><td>69.2</td><td>22.1</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 44.5</td><td>39.3</td><td>45.1</td><td>10.4</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 17.2</td><td>45.9</td><td>69.3</td><td> 9.3</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>151.5</td><td>41.3</td><td>58.5</td><td>18.5</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>180.8</td><td>10.8</td><td>58.4</td><td>12.9</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>  8.7</td><td>48.9</td><td>75.0</td><td> 7.2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & TV.Ad.Budget.... & Radio.Ad.Budget.... & Newspaper.Ad.Budget.... & Sales....\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 230.1 & 37.8 & 69.2 & 22.1\\\\\n",
       "\t2 &  44.5 & 39.3 & 45.1 & 10.4\\\\\n",
       "\t3 &  17.2 & 45.9 & 69.3 &  9.3\\\\\n",
       "\t4 & 151.5 & 41.3 & 58.5 & 18.5\\\\\n",
       "\t5 & 180.8 & 10.8 & 58.4 & 12.9\\\\\n",
       "\t6 &   8.7 & 48.9 & 75.0 &  7.2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | TV.Ad.Budget.... &lt;dbl&gt; | Radio.Ad.Budget.... &lt;dbl&gt; | Newspaper.Ad.Budget.... &lt;dbl&gt; | Sales.... &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 230.1 | 37.8 | 69.2 | 22.1 |\n",
       "| 2 |  44.5 | 39.3 | 45.1 | 10.4 |\n",
       "| 3 |  17.2 | 45.9 | 69.3 |  9.3 |\n",
       "| 4 | 151.5 | 41.3 | 58.5 | 18.5 |\n",
       "| 5 | 180.8 | 10.8 | 58.4 | 12.9 |\n",
       "| 6 |   8.7 | 48.9 | 75.0 |  7.2 |\n",
       "\n"
      ],
      "text/plain": [
       "  TV.Ad.Budget.... Radio.Ad.Budget.... Newspaper.Ad.Budget.... Sales....\n",
       "1 230.1            37.8                69.2                    22.1     \n",
       "2  44.5            39.3                45.1                    10.4     \n",
       "3  17.2            45.9                69.3                     9.3     \n",
       "4 151.5            41.3                58.5                    18.5     \n",
       "5 180.8            10.8                58.4                    12.9     \n",
       "6   8.7            48.9                75.0                     7.2     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# elimino la columna X dado que no aporta información\n",
    "base_publicidad$X <- NULL\n",
    "head(base_publicidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con eso queda comprobado que se eliminó la columna X, pero para efectos de simplicidad, es mejor cambiar el formato del nombre de las columnas, asi que procedo a hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>tv_ad_budget</th><th scope=col>radio_ad_budget</th><th scope=col>newspaper_ad_budget</th><th scope=col>sales</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>230.1</td><td>37.8</td><td>69.2</td><td>22.1</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 44.5</td><td>39.3</td><td>45.1</td><td>10.4</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 17.2</td><td>45.9</td><td>69.3</td><td> 9.3</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>151.5</td><td>41.3</td><td>58.5</td><td>18.5</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>180.8</td><td>10.8</td><td>58.4</td><td>12.9</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>  8.7</td><td>48.9</td><td>75.0</td><td> 7.2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & tv\\_ad\\_budget & radio\\_ad\\_budget & newspaper\\_ad\\_budget & sales\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 230.1 & 37.8 & 69.2 & 22.1\\\\\n",
       "\t2 &  44.5 & 39.3 & 45.1 & 10.4\\\\\n",
       "\t3 &  17.2 & 45.9 & 69.3 &  9.3\\\\\n",
       "\t4 & 151.5 & 41.3 & 58.5 & 18.5\\\\\n",
       "\t5 & 180.8 & 10.8 & 58.4 & 12.9\\\\\n",
       "\t6 &   8.7 & 48.9 & 75.0 &  7.2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | tv_ad_budget &lt;dbl&gt; | radio_ad_budget &lt;dbl&gt; | newspaper_ad_budget &lt;dbl&gt; | sales &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 230.1 | 37.8 | 69.2 | 22.1 |\n",
       "| 2 |  44.5 | 39.3 | 45.1 | 10.4 |\n",
       "| 3 |  17.2 | 45.9 | 69.3 |  9.3 |\n",
       "| 4 | 151.5 | 41.3 | 58.5 | 18.5 |\n",
       "| 5 | 180.8 | 10.8 | 58.4 | 12.9 |\n",
       "| 6 |   8.7 | 48.9 | 75.0 |  7.2 |\n",
       "\n"
      ],
      "text/plain": [
       "  tv_ad_budget radio_ad_budget newspaper_ad_budget sales\n",
       "1 230.1        37.8            69.2                22.1 \n",
       "2  44.5        39.3            45.1                10.4 \n",
       "3  17.2        45.9            69.3                 9.3 \n",
       "4 151.5        41.3            58.5                18.5 \n",
       "5 180.8        10.8            58.4                12.9 \n",
       "6   8.7        48.9            75.0                 7.2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cambio los nombre de las columnas\n",
    "colnames(base_publicidad) <- c(\"tv_ad_budget\", \"radio_ad_budget\",\n",
    "                               \"newspaper_ad_budget\", \"sales\")\n",
    "# reviso nuevamente los primeros registros\n",
    "head(base_publicidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y en efecto, ahora tengo la base de datos con las columnas bien nombradas, pero lo último eso si sería cambiar las escalas de:\n",
    "- Las 3 columnas independientes (tv_ad_budget, radio_ad_budget, newspaper_ad_budget) que estan actualmente en miles de dolares, la idea es pasarlas a dolares en unidades y no en escala de miles.\n",
    "- La columna dependiente (sales) que esta actualmente en millones de dolares, la idea es pasarla a dolares en unidades y no en escala de millones.\n",
    "\n",
    "Ajusto las escalas de las variables del dataset para que todas estén en dólares en lugar de miles de dólares o millones de dólares. Esto facilita la interpretación y comparación de los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>tv_ad_budget</th><th scope=col>radio_ad_budget</th><th scope=col>newspaper_ad_budget</th><th scope=col>sales</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>230100</td><td>37800</td><td>69200</td><td>22100000</td></tr>\n",
       "\t<tr><th scope=row>2</th><td> 44500</td><td>39300</td><td>45100</td><td>10400000</td></tr>\n",
       "\t<tr><th scope=row>3</th><td> 17200</td><td>45900</td><td>69300</td><td> 9300000</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>151500</td><td>41300</td><td>58500</td><td>18500000</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>180800</td><td>10800</td><td>58400</td><td>12900000</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>  8700</td><td>48900</td><td>75000</td><td> 7200000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & tv\\_ad\\_budget & radio\\_ad\\_budget & newspaper\\_ad\\_budget & sales\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 230100 & 37800 & 69200 & 22100000\\\\\n",
       "\t2 &  44500 & 39300 & 45100 & 10400000\\\\\n",
       "\t3 &  17200 & 45900 & 69300 &  9300000\\\\\n",
       "\t4 & 151500 & 41300 & 58500 & 18500000\\\\\n",
       "\t5 & 180800 & 10800 & 58400 & 12900000\\\\\n",
       "\t6 &   8700 & 48900 & 75000 &  7200000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | tv_ad_budget &lt;dbl&gt; | radio_ad_budget &lt;dbl&gt; | newspaper_ad_budget &lt;dbl&gt; | sales &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 230100 | 37800 | 69200 | 22100000 |\n",
       "| 2 |  44500 | 39300 | 45100 | 10400000 |\n",
       "| 3 |  17200 | 45900 | 69300 |  9300000 |\n",
       "| 4 | 151500 | 41300 | 58500 | 18500000 |\n",
       "| 5 | 180800 | 10800 | 58400 | 12900000 |\n",
       "| 6 |   8700 | 48900 | 75000 |  7200000 |\n",
       "\n"
      ],
      "text/plain": [
       "  tv_ad_budget radio_ad_budget newspaper_ad_budget sales   \n",
       "1 230100       37800           69200               22100000\n",
       "2  44500       39300           45100               10400000\n",
       "3  17200       45900           69300                9300000\n",
       "4 151500       41300           58500               18500000\n",
       "5 180800       10800           58400               12900000\n",
       "6   8700       48900           75000                7200000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cambiar la escala de las variables a dolares\n",
    "base_publicidad <- base_publicidad %>%\n",
    "  mutate(\n",
    "    tv_ad_budget = tv_ad_budget * 1000,\n",
    "    radio_ad_budget = radio_ad_budget * 1000,\n",
    "    newspaper_ad_budget = newspaper_ad_budget * 1000,\n",
    "    sales = sales * 1000000\n",
    "  )\n",
    "head(base_publicidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora veo que tengo los valores de las columnas en dolares y no en miles ni en millones de dolares, lo que me facilita la interpretación de las metricas para la posterior evaluación y comparación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo boxplots para visualizar la presencia de outliers en las variables del dataset. El proposito de hacer esto se divide en:\n",
    "\n",
    "- **Detección de Outliers**: Los boxplots son útiles para identificar valores atípicos (outliers) en las variables, que pueden influir en el rendimiento del modelo de regresión.\n",
    "- **Exploración de la Distribución**: Proporcionan una vista rápida de la distribución de los datos, incluyendo la mediana, el rango intercuartílico y los posibles outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Sales\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(scipen = 999)\n",
    "# Visualización de Outliers\n",
    "par(mfrow = c(2, 2))\n",
    "boxplot(base_publicidad$tv_ad_budget, main = \"TV Ad Budget\")\n",
    "boxplot(base_publicidad$radio_ad_budget, main = \"Radio Ad Budget\")\n",
    "boxplot(base_publicidad$newspaper_ad_budget, main = \"Newspaper Ad Budget\")\n",
    "boxplot(base_publicidad$sales, main = \"Sales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TV Ad Budget**: No presenta outliers significativos, con una distribución relativamente simétrica.\n",
    "- **Radio Ad Budget**: Similar al anterior, sin outliers significativos.\n",
    "- **Newspaper Ad Budget**: Presenta algunos outliers, lo que indica que hay valores extremos en el presupuesto de publicidad en periódicos.\n",
    "- **Sales**: No presenta outliers significativos, con una distribución bastante uniforme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El siguiente código calcula el rango intercuartílico (IQR) para la variable newspaper_ad_budget y detecta los outliers en base a este rango y a los limites inferior y superior. \n",
    "- Los outliers se identifican como valores que caen fuera de los límites inferior y superior calculados.\n",
    "- IQR = Q3- Q1 (Calculo el rango intercuartílico (IQR) como la diferencia entre el cuartil 3 (Q3) y el cuartil 1 (Q1)).\n",
    "- Limite Inferior = Calculo el límite inferior como Q1 menos 1.5 veces el IQR\n",
    "- Limite Superior = Calculo el límite superior como Q3 más 1.5 veces el IQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>tv_ad_budget</th><th scope=col>radio_ad_budget</th><th scope=col>newspaper_ad_budget</th><th scope=col>sales</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 67800</td><td>36600</td><td>114000</td><td>12500000</td></tr>\n",
       "\t<tr><td>296400</td><td>36300</td><td>100900</td><td>23800000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 4\n",
       "\\begin{tabular}{llll}\n",
       " tv\\_ad\\_budget & radio\\_ad\\_budget & newspaper\\_ad\\_budget & sales\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  67800 & 36600 & 114000 & 12500000\\\\\n",
       "\t 296400 & 36300 & 100900 & 23800000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 4\n",
       "\n",
       "| tv_ad_budget &lt;dbl&gt; | radio_ad_budget &lt;dbl&gt; | newspaper_ad_budget &lt;dbl&gt; | sales &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "|  67800 | 36600 | 114000 | 12500000 |\n",
       "| 296400 | 36300 | 100900 | 23800000 |\n",
       "\n"
      ],
      "text/plain": [
       "  tv_ad_budget radio_ad_budget newspaper_ad_budget sales   \n",
       "1  67800       36600           114000              12500000\n",
       "2 296400       36300           100900              23800000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#calculo de rango intercuartilico de newspaper_ad_budget\n",
    "q1 <- quantile(base_publicidad$newspaper_ad_budget, 0.25)\n",
    "q3 <- quantile(base_publicidad$newspaper_ad_budget, 0.75)\n",
    "iqr <- q3 - q1\n",
    "lim_inf <- q1 - 1.5 * iqr\n",
    "lim_sup <- q3 + 1.5 * iqr\n",
    "# identifico los outliers\n",
    "outliers <- base_publicidad %>%\n",
    "  filter(newspaper_ad_budget < lim_inf | newspaper_ad_budget > lim_sup)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de filtrar los datos para identificar los outliers, que son los valores que caen fuera de los límites inferior y superior calculados, pude identificar los valores atípicos en la variable newspaper_ad_budget que podrían influir negativamente en el rendimiento del modelo de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalización\n",
    "\n",
    "Para lo siguiente quiero definir una función de normalización que se utilizará para escalar las variables en el rango de 0 a 1. La normalización es un paso importante en el preprocesamiento de datos, especialmente en el contexto de machine learning, donde se busca que todas las variables estén en una escala comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Función de normalización\n",
    "normalizar <- function(x) {\n",
    "  return((x - min(x)) / (max(x) - min(x)))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito\n",
    "- Escalado de Variables: Asegurar que todas las variables en el dataset estén en la misma escala, lo cual es crucial para ciertos algoritmos de machine learning como la regresión lineal y k-NN.\n",
    "- Mejora del Rendimiento del Modelo: Reducir el sesgo introducido por las diferentes escalas de las variables, permitiendo al modelo aprender de manera más efectiva.\n",
    "\n",
    "Normalización de Variables\n",
    "\n",
    "Cada variable del dataset, cuando se pase a través de esta función, se transformará de tal manera que sus valores estarán entre 0 y 1. Esto es útil para eliminar el efecto de las diferentes escalas de las variables, facilitando el aprendizaje del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desnormalización\n",
    "\n",
    "El siguiente codigo define una función de desnormalización que se utilizará para revertir el proceso de normalización, devolviendo los datos a su escala original. La desnormalización es esencial cuando se interpretan los resultados de un modelo que ha sido entrenado en datos normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Función de desnormalización\n",
    "desnormalizar <- function(x, min_val, max_val) {\n",
    "  return(x * (max_val - min_val) + min_val)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito\n",
    "\n",
    "- Revertir la Normalización: Permitir que los resultados de los modelos entrenados en datos normalizados sean interpretados en la escala original de los datos.\n",
    "- Interpretación de Resultados: Facilitar la interpretación y comparación de los resultados del modelo en términos de las unidades originales de los datos.\n",
    "\n",
    "Resultados Esperados\n",
    "\n",
    "Cada variable que haya sido normalizada y luego se pase a través de esta función, se transformará de vuelta a su escala original, usando los valores mínimos y máximos originales. Esto es crucial para interpretar correctamente las predicciones del modelo.\n",
    "\n",
    "Implicaciones\n",
    "\n",
    "- Comprensibilidad: Los resultados del modelo se vuelven comprensibles en el contexto original, lo cual es importante para la toma de decisiones basadas en esos resultados.\n",
    "- Precisión en la Interpretación: Asegurar que las métricas de rendimiento del modelo (como RMSE, MAE) sean interpretadas correctamente en las unidades originales de las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para lo siguiente guardaré los valores mínimos y máximos originales de todas las columnas del conjunto de datos base_publicidad. Estos valores son esenciales para el proceso de normalización y desnormalización de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Guardar los valores mínimos y máximos originales de todas las columnas\n",
    "min_vals <- sapply(base_publicidad, min)\n",
    "max_vals <- sapply(base_publicidad, max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito\n",
    "\n",
    "**Normalización y Desnormalización**: Estos valores se utilizan para normalizar los datos (escalar los valores entre 0 y 1) y posteriormente desnormalizar las predicciones del modelo a su escala original.\n",
    "\n",
    "**Consistencia**: Asegurar que los mismos valores de referencia se usen en todo el proceso de modelado para mantener la consistencia en las transformaciones.\n",
    "\n",
    "Resultados\n",
    "\n",
    "- min_vals: Contiene los valores mínimos de cada columna en base_publicidad.\n",
    "- max_vals: Contiene los valores máximos de cada columna en base_publicidad.\n",
    "\n",
    "Uso en Normalización y Desnormalización\n",
    "\n",
    "Estos valores se utilizarán en las funciones de normalización y desnormalización para transformar los datos de manera consistente y precisa.\n",
    "\n",
    "Implementación en el Código\n",
    "\n",
    "Los valores mínimos y máximos se utilizan antes y después de la aplicación del modelo para asegurar que los datos se manejen correctamente durante todo el flujo de trabajo de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda normaliza todas las columnas del conjunto de datos base_publicidad utilizando la función normalizar, osea hace que todos los valores de las columnas esten entre 0 y 1, donde el valor 0 será el minimo valor para una cierta columna y el 1 será el valor máximo para una cierta columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>tv_ad_budget</th><th scope=col>radio_ad_budget</th><th scope=col>newspaper_ad_budget</th><th scope=col>sales</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.77578627</td><td>0.7620968</td><td>0.6059807</td><td>0.8070866</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.14812310</td><td>0.7923387</td><td>0.3940193</td><td>0.3464567</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.05579980</td><td>0.9254032</td><td>0.6068602</td><td>0.3031496</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.50997633</td><td>0.8326613</td><td>0.5118734</td><td>0.6653543</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.60906324</td><td>0.2177419</td><td>0.5109938</td><td>0.4448819</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.02705445</td><td>0.9858871</td><td>0.6569921</td><td>0.2204724</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & tv\\_ad\\_budget & radio\\_ad\\_budget & newspaper\\_ad\\_budget & sales\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 0.77578627 & 0.7620968 & 0.6059807 & 0.8070866\\\\\n",
       "\t2 & 0.14812310 & 0.7923387 & 0.3940193 & 0.3464567\\\\\n",
       "\t3 & 0.05579980 & 0.9254032 & 0.6068602 & 0.3031496\\\\\n",
       "\t4 & 0.50997633 & 0.8326613 & 0.5118734 & 0.6653543\\\\\n",
       "\t5 & 0.60906324 & 0.2177419 & 0.5109938 & 0.4448819\\\\\n",
       "\t6 & 0.02705445 & 0.9858871 & 0.6569921 & 0.2204724\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | tv_ad_budget &lt;dbl&gt; | radio_ad_budget &lt;dbl&gt; | newspaper_ad_budget &lt;dbl&gt; | sales &lt;dbl&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 0.77578627 | 0.7620968 | 0.6059807 | 0.8070866 |\n",
       "| 2 | 0.14812310 | 0.7923387 | 0.3940193 | 0.3464567 |\n",
       "| 3 | 0.05579980 | 0.9254032 | 0.6068602 | 0.3031496 |\n",
       "| 4 | 0.50997633 | 0.8326613 | 0.5118734 | 0.6653543 |\n",
       "| 5 | 0.60906324 | 0.2177419 | 0.5109938 | 0.4448819 |\n",
       "| 6 | 0.02705445 | 0.9858871 | 0.6569921 | 0.2204724 |\n",
       "\n"
      ],
      "text/plain": [
       "  tv_ad_budget radio_ad_budget newspaper_ad_budget sales    \n",
       "1 0.77578627   0.7620968       0.6059807           0.8070866\n",
       "2 0.14812310   0.7923387       0.3940193           0.3464567\n",
       "3 0.05579980   0.9254032       0.6068602           0.3031496\n",
       "4 0.50997633   0.8326613       0.5118734           0.6653543\n",
       "5 0.60906324   0.2177419       0.5109938           0.4448819\n",
       "6 0.02705445   0.9858871       0.6569921           0.2204724"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalizar todas las columnas\n",
    "# dado que las categoricas ya estan normalizadas, al normalizar\n",
    "# todas las columnas, solo se normalizaran las numericas y las\n",
    "# categoricas se mantendran igual\n",
    "base_publicidad <- as.data.frame(lapply(base_publicidad, normalizar))\n",
    "# Verificar la normalización\n",
    "head(base_publicidad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y con esto compruebo que todos los valores de las columnas estan entre 0 y 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  tv_ad_budget    radio_ad_budget  newspaper_ad_budget     sales       \n",
       " Min.   :0.0000   Min.   :0.0000   Min.   :0.0000      Min.   :0.0000  \n",
       " Max.   :1.0000   Max.   :1.0000   Max.   :1.0000      Max.   :1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quiero verificar que todos mis columnas tengan como mínimo 0 y como máximo 1\n",
    "summary(base_publicidad)[c(1, 6), ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division en conjunto de datos de entrenamiento y prueba\n",
    "\n",
    "La siguiente celda divide el conjunto de datos normalizado base_publicidad en conjuntos de entrenamiento y prueba utilizando una división estratificada basada en la variable objetivo sales.\n",
    "\n",
    "Inserción de Semilla\n",
    "\n",
    "Establezco una semilla para asegurar la reproducibilidad de la división de los datos. Esto garantiza que los resultados sean consistentes cada vez que se ejecute el código.\n",
    "\n",
    "División Estratificada de los Datos\n",
    "\n",
    "Divido el conjunto de datos en entrenamiento y prueba con una proporción del 80% para entrenamiento y 20% para prueba, asegurando que la variable objetivo `sales` esté estratificada. Esto significa que la distribución de sales en los conjuntos de entrenamiento y prueba será similar a la distribución original.\n",
    "\n",
    "Asignación de Conjuntos de Entrenamiento y Prueba\n",
    "\n",
    "Extraigo el conjunto de entrenamiento a partir de la particion y lo guardo en la variable `entrenamiento`, y hago lo mismo en el caso del conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "set.seed(123) # inserto semilla\n",
    "# Divido el conjunto de datos en entrenamiento y prueba\n",
    "# donde el 80% de los datos son para entrenamiento y el 20% para prueba\n",
    "# y estratifico por la variable objetivo\n",
    "particiones <- initial_split(base_publicidad, prop = 0.8, strata = \"sales\")\n",
    "# Guardo los datos de entrenamiento y prueba\n",
    "# en dos variables diferentes\n",
    "entrenamiento <- training(particiones)\n",
    "prueba <- testing(particiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito\n",
    "\n",
    "- Reproducibilidad: Usar set.seed(123) asegura que la división de los datos sea reproducible y que los resultados sean consistentes en ejecuciones diferentes del código.\n",
    "- Validación Apropiada: Dividir los datos en conjuntos de entrenamiento y prueba permite una validación adecuada del modelo. El conjunto de entrenamiento se utiliza para ajustar el modelo, y el conjunto de prueba se utiliza para evaluar su rendimiento.\n",
    "- Estratificación: Asegura que la distribución de la variable objetivo sales sea similar en ambos conjuntos, lo que ayuda a obtener una evaluación más representativa del rendimiento del modelo.\n",
    "\n",
    "Resultados\n",
    "\n",
    "División de Datos\n",
    "\n",
    "- Conjunto de Entrenamiento: Contendrá aproximadamente el 80% de los datos originales.\n",
    "- Conjunto de Prueba: Contendrá aproximadamente el 20% de los datos originales.\n",
    "- Distribución Similar: La distribución de la variable sales será similar en ambos conjuntos debido a la estratificación.\n",
    "\n",
    "Impacto en el Modelado\n",
    "\n",
    "- Generalización del Modelo: Evaluar el modelo en un conjunto de prueba separado del conjunto de entrenamiento proporciona una estimación más realista de su capacidad de generalización a nuevos datos.\n",
    "- Minimización del Sesgo de Selección: La estratificación asegura que los subconjuntos de datos mantengan la misma distribución de la variable objetivo, reduciendo el sesgo en la evaluación del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demostracion de distribuciones de la variable objetivo\n",
    "\n",
    "La siguiente celda de código genera un gráfico de densidad para comparar la distribución de la variable objetivo sales en el conjunto de datos original, el conjunto de entrenamiento y el conjunto de prueba. El propósito de esta visualización es asegurar que la estratificación se realizó correctamente y que las distribuciones de la variable objetivo son similares en todos los conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "Plot with title \"Distribucion\""
      ]
     },
     "metadata": {
      "image/png": {
       "height": 420,
       "width": 420
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# quiero comprobar la distribución de la variable objetivo\n",
    "# en los conjuntos original, de entrenamiento y de prueba\n",
    "# con un gráfico de densidad sin ocupar ggplot\n",
    "plot(density(base_publicidad$sales), col = \"black\", main = \"Distribucion\")\n",
    "lines(density(entrenamiento$sales), col = \"red\")\n",
    "lines(density(prueba$sales), col = \"blue\")\n",
    "legend(\"topright\", c(\"Original\", \"Entrenamiento\", \"Prueba\"),\n",
    "       fill = c(\"black\", \"red\", \"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito\n",
    "\n",
    "- Validación de la Estratificación: Verifico que la distribución de la variable objetivo sales es similar en los conjuntos de datos original, de entrenamiento y de prueba. Esto asegura que la estratificación se realizó correctamente y que los conjuntos de datos son representativos.\n",
    "- Evaluación Visual: Este gráfico proporciona una evaluación visual clara y fácil de interpretar de la distribución de la variable objetivo en diferentes conjuntos de datos.\n",
    "\n",
    "Resultados\n",
    "\n",
    "Visualización de la Distribución\n",
    "\n",
    "- Líneas de Densidad Similares: Las líneas de densidad para los conjuntos de datos original, de entrenamiento y de prueba son muy similares, indicando que la variable objetivo sales tiene una distribución similar en todos los conjuntos de datos.\n",
    "\n",
    "Impacto en el Modelado\n",
    "\n",
    "- Confiabilidad del Modelo: Al ya asegurarme que las distribuciones de la variable objetivo son similares en todos los conjuntos de datos contribuye a la confiabilidad del modelo, ya que indica que el conjunto de prueba es representativo del conjunto de datos original.\n",
    "\n",
    "- Reducción del Sesgo de Evaluación: La similitud en las distribuciones asegura que las evaluaciones del modelo no estan sesgadas por diferencias en la distribución de la variable objetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialización de vectores de metricas y del modelamiento del entrenamiento\n",
    "\n",
    "La siguiente celda de código inicializa varios vectores que se utilizarán para almacenar los resultados del método de remuestreo Jackknife durante su ejecución. La inicialización de estos vectores es un paso esencial para preparar el almacenamiento de las predicciones, errores y métricas de rendimiento que se calcularán en el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializar vectores para almacenar resultados\n",
    "n <- nrow(entrenamiento)\n",
    "predicciones <- numeric(n)\n",
    "errors <- numeric(n)\n",
    "rmse_values <- numeric(n)\n",
    "mae_values <- numeric(n)\n",
    "me_values <- numeric(n)  # Para el sesgo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito\n",
    "\n",
    "- Preparación para el Remuestreo Jackknife: Estos vectores permiten almacenar las métricas de rendimiento y los errores calculados durante cada iteración del método Jackknife.\n",
    "- Evaluación del Modelo: Almacenan los resultados en vectores facilita el cálculo de métricas de rendimiento promedio y la evaluación de la variabilidad y el sesgo del modelo.\n",
    "\n",
    "Resultados\n",
    "\n",
    "- Vectores Inicializados: Los vectores estan correctamente inicializados y listos para almacenar los resultados del método Jackknife.\n",
    "- Almacenamiento Eficiente: La inicialización de los vectores asegura que el almacenamiento de los resultados sea eficiente y organizado.\n",
    "\n",
    "Impacto en el Modelado\n",
    "\n",
    "- Facilita el Cálculo de Métricas: Tener vectores inicializados permite un cálculo más sencillo y organizado de las métricas de rendimiento, lo que facilita la evaluación del modelo.\n",
    "- Organización de Resultados: Almacenar los resultados de manera estructurada facilita la comparación y análisis de las métricas entre diferentes iteraciones del método Jackknife y otros métodos de remuestreo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones de calculos de metricas\n",
    "\n",
    "La siguiente celda de código define tres funciones para calcular diferentes métricas de rendimiento del modelo. Estas funciones serán utilizadas posteriormente para evaluar el rendimiento del modelo de regresión lineal en términos de error cuadrático medio (RMSE), error absoluto medio (MAE) y error medio (ME)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Funciones para calcular métricas\n",
    "rmse <- function(actual, predicted) {\n",
    "  sqrt(mean((actual - predicted)^2))\n",
    "}\n",
    "\n",
    "mae <- function(actual, predicted) {\n",
    "  mean(abs(actual - predicted))\n",
    "}\n",
    "\n",
    "me <- function(actual, predicted) {\n",
    "  mean(actual - predicted)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito\n",
    "\n",
    "- Evaluación del Rendimiento del Modelo: Estas funciones permiten calcular las métricas clave para evaluar la precisión y el sesgo del modelo de regresión lineal.\n",
    "- Comparación de Resultados: Proveer funciones para calcular RMSE, MAE y ME facilita la comparación del rendimiento del modelo entre diferentes métodos de remuestreo.\n",
    "\n",
    "Detalles de las Funciones\n",
    "\n",
    "`rmse`:\n",
    "Calcula la raíz cuadrada de la media de los cuadrados de las diferencias entre los valores reales y predichos.\n",
    "Es sensible a grandes errores debido a la naturaleza cuadrática del cálculo.\n",
    "\n",
    "`mae`:\n",
    "Calcula la media de los valores absolutos de las diferencias entre los valores reales y predichos.\n",
    "Es menos sensible a grandes errores en comparación con RMSE.\n",
    "\n",
    "`me`:\n",
    "Calcula la media de las diferencias entre los valores reales y predichos.\n",
    "Proporciona una medida del sesgo del modelo, indicando si el modelo tiende a sobreestimar o subestimar los valores reales.\n",
    "\n",
    "Resultados Esperados\n",
    "\n",
    "- Cálculo Preciso de Métricas: Las funciones definidas permitirán calcular de manera precisa y consistente las métricas de rendimiento del modelo.\n",
    "- Evaluación del Sesgo y la Precisión: Las métricas calculadas ayudarán a evaluar el sesgo y la precisión del modelo de regresión lineal.\n",
    "\n",
    "Impacto en el Modelado\n",
    "\n",
    "- Evaluación Integral del Modelo: Calcular múltiples métricas permite una evaluación más completa del rendimiento del modelo, considerando tanto la precisión (RMSE, MAE) como el sesgo (ME).\n",
    "- Facilita la Comparación: Definir estas funciones facilita la comparación del rendimiento del modelo entre diferentes métodos de remuestreo y en diferentes iteraciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda implementa el procedimiento de remuestreo Jackknife para evaluar el rendimiento del modelo de regresión lineal utilizando el conjunto de datos de entrenamiento. El objetivo es estimar la variabilidad, el sesgo y la precisión del modelo eliminando sistemáticamente una observación a la vez y calculando las predicciones y métricas de rendimiento para cada subconjunto en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Loop del metodo de remuestre Jackknife y entrenamiento de modelo\n",
    "start_time_jackknife <- Sys.time()\n",
    "\n",
    "for (i in 1:n) {\n",
    "  jackknife_train_data <- entrenamiento[-i, ]\n",
    "\n",
    "  modelo <- lm(sales ~ ., data = jackknife_train_data)\n",
    "\n",
    "  # Predicción para el conjunto de prueba\n",
    "  pred <- predict(modelo, newdata = prueba)\n",
    "  pred <- desnormalizar(pred, min_vals[\"sales\"], max_vals[\"sales\"])\n",
    "\n",
    "  # Calculo del error y las métricas para el conjunto de prueba\n",
    "  actual <- desnormalizar(prueba$sales, min_vals[\"sales\"], max_vals[\"sales\"])\n",
    "  errors <- actual - pred\n",
    "  rmse_values[i] <- rmse(actual, pred)\n",
    "  mae_values[i] <- mae(actual, pred)\n",
    "  me_values[i] <- me(actual, pred)\n",
    "}\n",
    "\n",
    "end_time_jackknife <- Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito:\n",
    "\n",
    "Evaluar el rendimiento del modelo de regresión lineal utilizando el método de remuestreo Jackknife. Este método permite estimar la variabilidad, el sesgo y la precisión del modelo.\n",
    "\n",
    "Detalles del Proceso:\n",
    "\n",
    "- Inicio del Temporizador:\n",
    "- `start_time_jackknife <- Sys.time()`: Registra el tiempo inicial para medir la duración total del proceso de Jackknife.\n",
    "\n",
    "- Bucle Principal:\n",
    "- Iteraciones: El bucle se ejecuta n veces, donde n es el número de observaciones en el conjunto de datos de entrenamiento.\n",
    "- Creación de Submuestras:\n",
    "- `jackknife_train_data <- entrenamiento[-i, ]`: Excluye la i-ésima observación del conjunto de entrenamiento.\n",
    "- Entrenamiento del Modelo:\n",
    "- `modelo <- lm(sales ~ ., data = jackknife_train_data)`: Entrena un modelo de regresión lineal con el conjunto de entrenamiento modificado.\n",
    "- Predicción y Desnormalización:\n",
    "- `pred <- predict(modelo, newdata = prueba)`: Predice la variable objetivo para el conjunto de prueba.\n",
    "- `pred <- desnormalizar(pred, min_vals[\"sales\"], max_vals[\"sales\"])`: Desnormaliza la predicción para que esté en la escala original.\n",
    "- Cálculo de Métricas:\n",
    "- `actual <- desnormalizar(prueba$sales, min_vals[\"sales\"], max_vals[\"sales\"])`: Desnormaliza los valores reales del conjunto de prueba.\n",
    "- `errors <- actual - pred`: Calcula y almacena el error.\n",
    "- `rmse_values[i] <- rmse(actual, pred)`: Calcula y almacena el RMSE.\n",
    "- `mae_values[i] <- mae(actual, pred)`: Calcula y almacena el MAE.\n",
    "- `me_values[i] <- me(actual, pred)`: Calcula y almacena el ME.\n",
    "\n",
    "- Fin del Temporizador:\n",
    "- `end_time_jackknife <- Sys.time()`: Registra el tiempo final para medir la duración total del proceso de Jackknife.\n",
    "\n",
    "Impacto en los Objetivos y Alcances\n",
    "\n",
    "1. Implementación del Método Jackknife:\n",
    "\n",
    "Realiza el proceso completo de Jackknife para evaluar el rendimiento del modelo de regresión lineal.\n",
    "Permite estimar la variabilidad, el sesgo y la precisión del modelo.\n",
    "\n",
    "2. Comparación con Otros Métodos de Remuestreo:\n",
    "\n",
    "Los resultados obtenidos (predicciones, errores y métricas de rendimiento) serán comparados posteriormente con los métodos de K-fold Cross Validation y Bootstrapping para evaluar sus ventajas y desventajas relativas.\n",
    "\n",
    "Resultados Esperados\n",
    "\n",
    "- Métricas de Rendimiento:\n",
    "- Se espera obtener valores para RMSE, MAE y ME que reflejen la precisión y el sesgo del modelo.\n",
    "- Variabilidad y Varianza:\n",
    "- La varianza de las predicciones y la desviación estándar proporcionarán una medida de la variabilidad del modelo.\n",
    "- Tiempo de Ejecución:\n",
    "- Se espera que el tiempo de ejecución del método Jackknife sea más eficiente en comparación con el Bootstrapping, pero puede variar según el tamaño del conjunto de datos.\n",
    "Análisis Posterior\n",
    "- Comparación de Resultados:\n",
    "- Los valores calculados en esta celda se utilizarán para comparar la precisión, la variabilidad y el sesgo del modelo con los resultados obtenidos mediante K-fold Cross Validation y Bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Razones para utilizar el conjunto de prueba en predicciones\n",
    "\n",
    "1. Evaluación General del Modelo:\n",
    "\n",
    "- Objetivo: Comprobar la variabilidad, el sesgo y la varianza del estimador utilizando el dataset.\n",
    "- Razón: Utilizar el conjunto de prueba permite evaluar cómo generaliza el modelo a datos no vistos previamente. Esto es crucial para entender el rendimiento real del modelo fuera de la muestra de entrenamiento, lo que es más representativo del desempeño en situaciones del mundo real.\n",
    "\n",
    "2. Consistencia en la Evaluación:\n",
    "\n",
    "- Objetivo: Evaluar y comparar las métricas de rendimiento y su precisión entre los métodos de remuestreo.\n",
    "- Razón: Al usar un conjunto de prueba consistente y separado, se asegura que las métricas de rendimiento (como RMSE y MAE) sean comparables entre diferentes métodos de remuestreo (Jackknife, K-fold, Bootstrapping). Esto proporciona una base común para la comparación.\n",
    "\n",
    "3. Prevención de Overfitting:\n",
    "\n",
    "- Objetivo: Implementar el método de remuestreo Jackknife para evaluar el rendimiento de un modelo de regresión lineal.\n",
    "- Razón: Predicciones realizadas en el conjunto de prueba ayudan a detectar si el modelo ha overfit al conjunto de entrenamiento. Usar solo el conjunto de validación (filas i-ésimas) podría no captar esta diferencia, ya que esas observaciones todavía forman parte del mismo conjunto de entrenamiento.\n",
    "\n",
    "4. Medición de Generalización:\n",
    "\n",
    "- Objetivo: Comprobar la variabilidad, el sesgo y la varianza del estimador.\n",
    "- Razón: La variabilidad, el sesgo y la varianza deben ser evaluados en un contexto que simule la aplicación real del modelo. Esto implica utilizar un conjunto de datos que no fue utilizado en el ajuste del modelo (es decir, el conjunto de prueba).\n",
    "\n",
    "5. Comparacion con otros metodos:\n",
    "\n",
    "- Objetivo: Comparar el método Jackknife con otros métodos de remuestreo.\n",
    "- Razón: Para comparar correctamente diferentes métodos de remuestreo, es necesario mantener un conjunto de prueba separado. Esto garantiza que cualquier evaluación de la varianza y el sesgo no esté influenciada por la variabilidad introducida en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente celda calcula las métricas promedio de rendimiento y la varianza de las predicciones obtenidas mediante el método de remuestreo Jackknife. Estas métricas permiten evaluar la precisión, el sesgo y la variabilidad del modelo de regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculo de métricas promedio y varianza\n",
    "avg_rmse <- mean(rmse_values)\n",
    "avg_mae <- mean(mae_values)\n",
    "avg_me <- mean(me_values)\n",
    "var_pred_jackknife <- var(pred)\n",
    "sd_pred_jackknife <- sd(pred)\n",
    "time_jackknife <- end_time_jackknife - start_time_jackknife"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito:\n",
    "\n",
    "Calcular las métricas de rendimiento (RMSE, MAE, ME), la varianza y la desviación estándar de las predicciones, así como el tiempo total de ejecución del método Jackknife.\n",
    "\n",
    "Impacto en los Objetivos y Alcances\n",
    "\n",
    "Estimación de Variabilidad, Sesgo y Varianza:\n",
    "\n",
    "- Permite evaluar la variabilidad, el sesgo y la precisión del modelo de regresión lineal utilizando las métricas calculadas.\n",
    "- Proporciona una medida clara del rendimiento del modelo mediante el cálculo de RMSE, MAE, ME, varianza y desviación estándar.\n",
    "\n",
    "Comparación con Otros Métodos de Remuestreo:\n",
    "\n",
    "Las métricas calculadas se utilizarán para comparar el rendimiento del modelo con los resultados obtenidos mediante K-fold Cross Validation y Bootstrapping.\n",
    "\n",
    "Resultados Esperados\n",
    "\n",
    "- Métricas de Rendimiento:\n",
    "Valores para RMSE, MAE y ME que reflejen la precisión y el sesgo del modelo.\n",
    "Variabilidad y Varianza:\n",
    "La varianza de las predicciones y la desviación estándar proporcionarán una medida de la variabilidad del modelo.\n",
    "- Tiempo de Ejecución:\n",
    "Se espera que el tiempo de ejecución del método Jackknife sea eficiente en comparación con otros métodos de remuestreo, como el Bootstrapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife RMSE Promedio: 1569260 \n",
      "Jackknife MAE Promedio: 1158544 \n",
      "Jackknife ME Promedio (Sesgo): 82700.18 \n",
      "Jackknife Varianza de Predicciones: 20352271415059 \n",
      "Jackknife Desviación Estándar de Predicciones: 4511349 \n",
      "Jackknife Tiempo de Ejecución: 0.309577 \n"
     ]
    }
   ],
   "source": [
    "# Resultados Jackknife\n",
    "cat(\"Jackknife RMSE Promedio:\", avg_rmse, \"\\n\")\n",
    "cat(\"Jackknife MAE Promedio:\", avg_mae, \"\\n\")\n",
    "cat(\"Jackknife ME Promedio (Sesgo):\", avg_me, \"\\n\")\n",
    "cat(\"Jackknife Varianza de Predicciones:\", format(var_pred_jackknife,\n",
    "                                                  scientific = FALSE), \"\\n\")\n",
    "cat(\"Jackknife Desviación Estándar de Predicciones:\", sd_pred_jackknife, \"\\n\")\n",
    "cat(\"Jackknife Tiempo de Ejecución:\", time_jackknife, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación y Evaluación\n",
    "\n",
    "1. **RMSE Promedio (Root Mean Squared Error):** \n",
    "   - **Valor:** 1569260\n",
    "   - **Análisis:** Este valor indica que, en promedio, las predicciones del modelo se desvían del valor real en aproximadamente 1,569,260 dólares. Un RMSE de esta magnitud sugiere que el modelo tiene un error considerable en sus predicciones, lo cual podría ser debido a la complejidad de los datos o a una falta de ajuste del modelo. Comparado con un RMSE ideal más bajo, este valor indica que hay margen de mejora en la precisión del modelo.\n",
    "\n",
    "2. **MAE Promedio (Mean Absolute Error):** \n",
    "   - **Valor:** 1158544\n",
    "   - **Análisis:** El MAE promedio de aproximadamente 1,158,544 dólares muestra la magnitud promedio del error sin considerar la dirección. Al igual que el RMSE, este valor es alto, lo que sugiere que el modelo no está prediciendo con alta precisión y que los errores son significativos.\n",
    "\n",
    "3. **ME Promedio (Mean Error) - Sesgo:**\n",
    "   - **Valor:** 82700.18\n",
    "   - **Análisis:** El sesgo promedio de 82,700.18 dólares indica que, en promedio, el modelo tiende a sobrestimar las predicciones. Aunque no es extremadamente alto en comparación con el RMSE y el MAE, un sesgo cercano a cero sería preferible. Este sesgo podría ser indicativo de un problema sistemático en el modelo.\n",
    "\n",
    "4. **Varianza de las Predicciones:**\n",
    "   - **Valor:** 20352271415059\n",
    "   - **Análisis:** La varianza de las predicciones es extremadamente alta, lo que indica que hay una gran dispersión en las predicciones del modelo. Esto sugiere que el modelo no es consistente en sus predicciones y que podría estar sobreajustándose a los datos de entrenamiento, resultando en una alta variabilidad.\n",
    "\n",
    "5. **Desviación Estándar de las Predicciones:**\n",
    "   - **Valor:** 4511349\n",
    "   - **Análisis:** La desviación estándar complementa la varianza y también es alta, lo que confirma la gran dispersión de las predicciones alrededor de la media. Una alta desviación estándar sugiere que las predicciones del modelo son muy variables y poco confiables.\n",
    "\n",
    "6. **Tiempo de Ejecución:**\n",
    "   - **Valor:** 0.192606 segundos\n",
    "   - **Análisis:** El tiempo total de ejecución del procedimiento de Jackknife fue de aproximadamente 0.19 segundos. Este resultado demuestra la eficiencia computacional del método Jackknife. En comparación con otros métodos de remuestreo como Bootstrapping, que generalmente requiere más tiempo, Jackknife es rápido y eficiente.\n",
    "\n",
    "#### Impacto en los Objetivos y Alcances\n",
    "\n",
    "1. **Estimación de Variabilidad, Sesgo y Varianza:**\n",
    "   - Las métricas calculadas (RMSE, MAE, ME, varianza y desviación estándar) proporcionan una evaluación completa del rendimiento del modelo de regresión lineal en términos de precisión, sesgo y variabilidad. Los altos valores de RMSE, MAE y desviación estándar sugieren que el modelo tiene un rendimiento subóptimo y una alta variabilidad en sus predicciones.\n",
    "\n",
    "2. **Comparación con Otros Métodos de Remuestreo:**\n",
    "   - Estos resultados serán comparados con los métodos de K-fold Cross Validation y Bootstrapping para evaluar sus ventajas y desventajas relativas en términos de precisión, sesgo, varianza y eficiencia computacional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definicion de control de entrenamiento de k-fold CV y sus parametros\n",
    "\n",
    "En la siguiente celda, se define el control de entrenamiento para aplicar K-fold Cross Validation al modelo de regresión lineal. K-fold Cross Validation es un método de remuestreo que divide el conjunto de datos en K partes (folds) de manera que cada fold es utilizado una vez como conjunto de validación mientras los K-1 folds restantes se utilizan como conjunto de entrenamiento. Este proceso se repite K veces, asegurando que cada fold se utilice como conjunto de validación una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# K-fold Cross Validation\n",
    "# Definir control de entrenamiento con k-fold CV\n",
    "train_control <- trainControl(method = \"cv\", number = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivo\n",
    "\n",
    "Configura el método de validación cruzada (cross-validation) con 10 folds.\n",
    "\n",
    "Detalles\n",
    "\n",
    "- method = \"cv\": Indica que se utilizará la validación cruzada.\n",
    "- number = 10: Especifica que se realizarán 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de ejecución\n",
    "start_time_cv <- Sys.time()\n",
    "# Entrenar el modelo usando k-fold CV\n",
    "modelo_cv <- train(sales ~ ., data = entrenamiento, method = \"lm\",\n",
    "                   trControl = train_control)\n",
    "end_time_cv <- Sys.time()\n",
    "# Predicciones en el conjunto de prueba\n",
    "predicciones_cv <- predict(modelo_cv, newdata = prueba)\n",
    "predicciones_cv <- desnormalizar(predicciones_cv, min_vals[\"sales\"],\n",
    "                                 max_vals[\"sales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la celda se implementó el entrenamiento del modelo de regresión lineal utilizando K-fold Cross Validation, se mide el tiempo de ejecución del proceso, y se realizan predicciones en el conjunto de prueba.\n",
    "\n",
    "1. `start_time_cv` <- Sys.time():\n",
    "\n",
    "- Objetivo: Registrar el tiempo inicial para medir la duración total del proceso de K-fold Cross Validation.\n",
    "- Impacto en los Objetivos: Ayuda a evaluar la eficiencia computacional del método K-fold CV en comparación con Jackknife y Bootstrapping.\n",
    "\n",
    "2. Entrenamiento del Modelo:\n",
    "\n",
    "- `modelo_cv <- train(sales ~ ., data = entrenamiento, method = \"lm\", trControl = train_control)`:\n",
    "- Objetivo: Entrenar el modelo de regresión lineal utilizando K-fold Cross Validation.\n",
    "- Detalles:\n",
    "- `sales ~ .`: Formula que indica que sales es la variable dependiente y todas las demás son las variables independientes.\n",
    "- `data = entrenamiento`: El conjunto de datos de entrenamiento.\n",
    "- `method = \"lm\"`: Especifica que se usará un modelo de regresión lineal.\n",
    "- `trControl = train_control`: Utiliza la configuración de K-fold CV definida anteriormente.\n",
    "Impacto en los Objetivos: Permite evaluar la precisión, la variabilidad y el sesgo del modelo de regresión lineal utilizando K-fold Cross Validation.\n",
    "\n",
    "3. `end_time_cv <- Sys.time()`:\n",
    "\n",
    "- Objetivo: Registrar el tiempo final para medir la duración total del proceso de K-fold Cross Validation.\n",
    "- Impacto en los Objetivos: Ayuda a evaluar la eficiencia computacional del método K-fold CV en comparación con Jackknife y Bootstrapping.\n",
    "\n",
    "4. Predicciones en el Conjunto de Prueba:\n",
    "\n",
    "- `predicciones_cv <- predict(modelo_cv, newdata = prueba)`:\n",
    "- Objetivo: Realizar predicciones en el conjunto de prueba utilizando el modelo entrenado.\n",
    "Impacto en los Objetivos: Evaluar la precisión del modelo en datos no vistos durante el entrenamiento.\n",
    "- `predicciones_cv <- desnormalizar(predicciones_cv, min_vals[\"sales\"], max_vals[\"sales\"])`:\n",
    "- Objetivo: Desnormalizar las predicciones para que estén en la escala original.\n",
    "- Impacto en los Objetivos: Asegura que las predicciones estén en la escala correcta para una evaluación precisa.\n",
    "\n",
    "Resultados\n",
    "\n",
    "- Predicciones Desnormalizadas: Predicciones del modelo en el conjunto de prueba en la escala original.\n",
    "- Tiempo de Ejecución: Duración total del proceso de K-fold Cross Validation, que se utilizará para evaluar la eficiencia computacional en comparación con Jackknife y Bootstrapping.\n",
    "- Métricas de Rendimiento: Los resultados obtenidos (predicciones, errores y métricas de rendimiento) se utilizarán para comparar la efectividad de los métodos de remuestreo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculo de Metricas y print de resultados, para K-fold CV\n",
    "\n",
    "En esta celda se calculan las métricas de evaluación para el modelo de regresión lineal utilizando K-fold Cross Validation, y se muestran los resultados.\n",
    "\n",
    "Cálculo de Métricas de Evaluación:\n",
    "\n",
    "- `rmse_cv`: Calcula el RMSE (Root Mean Square Error) de las predicciones desnormalizadas del conjunto de validación.\n",
    "- `mae_cv`: Calcula el MAE (Mean Absolute Error) de las predicciones desnormalizadas del conjunto de validación.\n",
    "- `me_cv`: Calcula el ME (Mean Error) de las predicciones desnormalizadas del conjunto de validación.\n",
    "- `var_pred_cv`: Calcula la varianza de las predicciones del modelo.\n",
    "- `sd_pred_cv`: Calcula la desviación estándar de las predicciones del modelo.\n",
    "- `time_cv`: Calcula el tiempo total de ejecución del proceso de K-fold Cross Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-fold CV RMSE: 1569045 \n",
      "K-fold CV MAE: 1158506 \n",
      "K-fold CV ME (Sesgo): 82743.14 \n",
      "K-fold CV Varianza de Predicciones: 20536362901454 \n",
      "K-fold CV Desviación Estándar de Predicciones: 4531706 \n",
      "K-fold CV Tiempo de Ejecución: 0.127593 \n"
     ]
    }
   ],
   "source": [
    "# Calcular métricas de evaluación\n",
    "rmse_cv <- rmse(desnormalizar(prueba$sales, min_vals[\"sales\"],\n",
    "                              max_vals[\"sales\"]), predicciones_cv)\n",
    "mae_cv <- mae(desnormalizar(prueba$sales, min_vals[\"sales\"],\n",
    "                            max_vals[\"sales\"]), predicciones_cv)\n",
    "me_cv <- me(desnormalizar(prueba$sales, min_vals[\"sales\"],\n",
    "                          max_vals[\"sales\"]), predicciones_cv)\n",
    "var_pred_cv <- var(predicciones_cv)\n",
    "sd_pred_cv <- sd(predicciones_cv)\n",
    "time_cv <- end_time_cv - start_time_cv\n",
    "\n",
    "# Resultados K-fold CV\n",
    "cat(\"K-fold CV RMSE:\", rmse_cv, \"\\n\")\n",
    "cat(\"K-fold CV MAE:\", mae_cv, \"\\n\")\n",
    "cat(\"K-fold CV ME (Sesgo):\", me_cv, \"\\n\")\n",
    "cat(\"K-fold CV Varianza de Predicciones:\", format(var_pred_cv,\n",
    "                                                  scientific = FALSE), \"\\n\")\n",
    "cat(\"K-fold CV Desviación Estándar de Predicciones:\", sd_pred_cv, \"\\n\")\n",
    "cat(\"K-fold CV Tiempo de Ejecución:\", time_cv, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación de Resultados\n",
    "\n",
    "1. **K-fold CV RMSE (Root Mean Square Error):** \n",
    "   - **Valor:** 1,569,045\n",
    "   - **Interpretación:** El RMSE es una medida de la diferencia promedio cuadrática entre los valores predichos y los valores observados. Un RMSE de 1,569,045 indica que, en promedio, las predicciones del modelo se desvían del valor real por aproximadamente 1,569,045 unidades monetarias (dólares). Este valor proporciona una indicación de la precisión del modelo.\n",
    "\n",
    "2. **K-fold CV MAE (Mean Absolute Error):**\n",
    "   - **Valor:** 1,158,506\n",
    "   - **Interpretación:** El MAE mide la magnitud promedio de los errores en un conjunto de predicciones, sin considerar su dirección. Un MAE de 1,158,506 sugiere que las predicciones del modelo tienen un error promedio absoluto de 1,158,506 dólares.\n",
    "\n",
    "3. **K-fold CV ME (Mean Error - Sesgo):**\n",
    "   - **Valor:** 82,743.14\n",
    "   - **Interpretación:** El ME indica el sesgo promedio de las predicciones. Un ME positivo de 82,743.14 significa que, en promedio, las predicciones del modelo están sobreestimando los valores reales por aproximadamente 82,743.14 dólares.\n",
    "\n",
    "4. **K-fold CV Varianza de Predicciones:**\n",
    "   - **Valor:** 20,536,362,901,454\n",
    "   - **Interpretación:** La varianza de las predicciones mide la dispersión de las predicciones alrededor de su media. Una varianza de 20,536,362,901,454 indica una variabilidad considerable en las predicciones del modelo.\n",
    "\n",
    "5. **K-fold CV Desviación Estándar de Predicciones:**\n",
    "   - **Valor:** 4,531,706\n",
    "   - **Interpretación:** La desviación estándar de 4,531,706 refuerza la alta variabilidad en las predicciones, indicando que las predicciones del modelo pueden variar significativamente de una instancia a otra.\n",
    "\n",
    "6. **K-fold CV Tiempo de Ejecución:**\n",
    "   - **Valor:** 0.120523 segundos\n",
    "   - **Interpretación:** El tiempo de ejecución de K-fold CV es 0.120523 segundos, lo que sugiere que el método es relativamente eficiente en términos de tiempo computacional.\n",
    "\n",
    "#### Impacto en los Objetivos y Alcances\n",
    "\n",
    "- **Evaluación del Rendimiento del Modelo:** Las métricas de rendimiento obtenidas (RMSE, MAE, ME) proporcionan una evaluación detallada de la precisión y el sesgo del modelo de regresión lineal utilizando K-fold CV.\n",
    "- **Comparación de Métodos de Remuestreo:** Los resultados serán comparados con los obtenidos mediante los métodos Jackknife y Bootstrapping para evaluar sus ventajas y desventajas relativas en términos de precisión, sesgo, variabilidad y eficiencia computacional.\n",
    "- **Análisis de la Eficiencia Computacional:** El tiempo de ejecución del K-fold CV se comparará con el tiempo de ejecución de Jackknife y Bootstrapping para determinar su eficiencia computacional relativa.\n",
    "\n",
    "Los resultados del K-fold Cross Validation muestran una alta precisión y un sesgo moderado en el modelo de regresión lineal, con una variabilidad considerable en las predicciones. El tiempo de ejecución es relativamente corto, lo que indica una buena eficiencia computacional. Estos resultados se utilizarán para una comparación más amplia con los métodos Jackknife y Bootstrapping para evaluar el rendimiento global del modelo de regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definicion de control de entrenamiento de bootstrapoing y sus parametros\n",
    "\n",
    "El siguiente codigo establece los parámetros necesarios para llevar a cabo el remuestreo Bootstrapping en el proceso de entrenamiento del modelo de regresión lineal. Esto es fundamental para evaluar la variabilidad, el sesgo y la precisión del modelo.\n",
    "\n",
    "Detalles del Proceso\n",
    "\n",
    "- method = \"boot\": Especifica que el método de remuestreo a utilizar es Bootstrapping.\n",
    "- number = 200: Define el número de muestras bootstrap que se generarán durante el proceso de entrenamiento. Cada muestra será utilizada para entrenar y evaluar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "# Definir control de entrenamiento con bootstrapping\n",
    "train_control_boot <- trainControl(method = \"boot\", number = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Propósito:\n",
    "\n",
    "Establecer los parámetros necesarios para llevar a cabo el remuestreo Bootstrapping en el proceso de entrenamiento del modelo de regresión lineal. Esto es fundamental para evaluar la variabilidad, el sesgo y la precisión del modelo.\n",
    "\n",
    "Impacto en los Objetivos y Alcances\n",
    "\n",
    "1. Implementación del Método Bootstrapping:\n",
    "\n",
    "- Permite evaluar el rendimiento del modelo de regresión lineal mediante el remuestreo Bootstrapping.\n",
    "- Proporciona una estimación de la variabilidad y el sesgo del modelo al generar múltiples muestras con reemplazo del conjunto de datos original.\n",
    "\n",
    "2. Comparación con Otros Métodos de Remuestreo:\n",
    "\n",
    "- Los resultados obtenidos con Bootstrapping serán comparados con los métodos Jackknife y K-fold Cross Validation para evaluar las ventajas y desventajas relativas en términos de precisión, sesgo, variabilidad y eficiencia computacional.\n",
    "\n",
    "Beneficios de Bootstrapping\n",
    "\n",
    "- Estimación de la Variabilidad: Bootstrapping es especialmente útil para estimar la variabilidad del modelo, ya que genera múltiples muestras con reemplazo.\n",
    "- Reducción del Sesgo: Ayuda a reducir el sesgo del estimador al promediar los resultados de múltiples muestras bootstrap.\n",
    "- Flexibilidad: No hace suposiciones estrictas sobre la distribución de los datos, lo que lo hace aplicable a una amplia variedad de problemas de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento y medición de tiempo de ejecución\n",
    "\n",
    "La siguiente celda tiene como objetivo entrenar el modelo de regresión lineal utilizando el método de remuestreo Bootstrapping y medir el tiempo de ejecución del proceso. Esto es crucial para evaluar la eficiencia computacional del método Bootstrapping en comparación con otros métodos de remuestreo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Medir el tiempo de ejecución\n",
    "start_time_boot <- Sys.time()\n",
    "# Entrenar el modelo usando bootstrapping\n",
    "modelo_boot <- train(sales ~ ., data = entrenamiento, method = \"lm\",\n",
    "                     trControl = train_control_boot)\n",
    "end_time_boot <- Sys.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detalles del Proceso\n",
    "\n",
    "1. **Medición del Tiempo de Ejecución - Inicio:**\n",
    "    `start_time_boot <- Sys.time()`\n",
    "    - **Descripción:** Se registra el tiempo inicial antes de comenzar el entrenamiento del modelo. Esto permitirá calcular el tiempo total de ejecución del método Bootstrapping.\n",
    "\n",
    "2. **Entrenamiento del Modelo con Bootstrapping:**\n",
    "    `modelo_boot <- train(sales ~ ., data = entrenamiento, method = \"lm\", trControl = train_control_boot)`\n",
    "    - **Descripción:** Se entrena el modelo de regresión lineal utilizando el conjunto de datos de entrenamiento. El método `train` de la librería `caret` se utiliza con el control de entrenamiento definido previamente (`train_control_boot`), que especifica el uso del método de remuestreo Bootstrapping.\n",
    "    - **Propósito:** Evaluar cómo se comporta el modelo cuando se aplica Bootstrapping, un método de remuestreo que genera múltiples muestras con reemplazo del conjunto de datos original para evaluar la precisión y la variabilidad del modelo.\n",
    "\n",
    "3. **Medición del Tiempo de Ejecución - Fin:**\n",
    "    `end_time_boot <- Sys.time()`\n",
    "    - **Descripción:** Se registra el tiempo final después de completar el entrenamiento del modelo. Esto permitirá calcular el tiempo total de ejecución del método Bootstrapping.\n",
    "\n",
    "#### Impacto en los Objetivos y Alcances\n",
    "\n",
    "1. **Evaluar la Eficiencia Computacional:**\n",
    "    - **Objetivo 4:** Analizar la subestimación de la varianza en muestras pequeñas y comparar la eficiencia computacional de los métodos.\n",
    "    - **Objetivo 6:** Analizar la eficiencia computacional de cada método de remuestreo.\n",
    "    - El tiempo total de ejecución del Bootstrapping se comparará con los tiempos de ejecución de los otros métodos de remuestreo (Jackknife y K-fold CV) para evaluar cuál es más eficiente en términos computacionales.\n",
    "\n",
    "2. **Evaluar el Rendimiento del Modelo:**\n",
    "    - **Objetivo 3:** Comparar el método Jackknife con otros métodos de remuestreo como K-fold Cross Validation y Bootstrapping.\n",
    "    - El modelo entrenado con Bootstrapping se utilizará para predecir y calcular métricas de rendimiento (RMSE, MAE, ME) en las siguientes celdas.\n",
    "\n",
    "3. **Preparación para la Evaluación de Métricas:**\n",
    "    - Las predicciones del modelo entrenado con Bootstrapping se compararán con los valores reales del conjunto de prueba para evaluar el rendimiento y la variabilidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicciones y desnormalizacion en Bootstrapping\n",
    "\n",
    "La siguiente celda tiene como objetivo utilizar el modelo de regresión lineal entrenado con el método Bootstrapping para hacer predicciones sobre el conjunto de prueba. Además, se desnormalizan las predicciones para que estén en la escala original de la variable dependiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Predicciones en el conjunto de prueba\n",
    "predicciones_boot <- predict(modelo_boot, newdata = prueba)\n",
    "predicciones_boot <- desnormalizar(predicciones_boot,\n",
    "                                   min_vals[\"sales\"], max_vals[\"sales\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detalles del Proceso\n",
    "\n",
    "1. **Predicciones en el Conjunto de Prueba:**\n",
    "    `predicciones_boot <- predict(modelo_boot, newdata = prueba)`\n",
    "    - **Descripción:** Utiliza el modelo de regresión lineal entrenado con Bootstrapping (`modelo_boot`) para predecir los valores de la variable dependiente (`sales`) en el conjunto de prueba (`prueba`).\n",
    "    - **Propósito:** Evaluar la precisión del modelo utilizando datos no vistos durante el entrenamiento, lo que proporciona una medida de cómo generaliza el modelo a datos nuevos.\n",
    "\n",
    "2. **Desnormalización de las Predicciones:**\n",
    "    `predicciones_boot <- desnormalizar(predicciones_boot, min_vals[\"sales\"], max_vals[\"sales\"])`\n",
    "    - **Descripción:** Convierte las predicciones normalizadas de nuevo a su escala original utilizando los valores mínimos y máximos de la columna `sales` del conjunto de datos original.\n",
    "    - **Propósito:** Facilitar la interpretación de los resultados y asegurar que las métricas de rendimiento (como RMSE y MAE) sean calculadas en la escala original de la variable dependiente.\n",
    "\n",
    "#### Impacto en los Objetivos y Alcances\n",
    "\n",
    "1. **Evaluar el Rendimiento del Modelo:**\n",
    "    - **Objetivo 3:** Comparar el método Jackknife con otros métodos de remuestreo como K-fold Cross Validation y Bootstrapping.\n",
    "    - Las predicciones desnormalizadas se utilizarán para calcular métricas de rendimiento como RMSE, MAE y ME, lo que permitirá comparar la precisión del modelo entrenado con Bootstrapping con los modelos entrenados con Jackknife y K-fold CV.\n",
    "\n",
    "2. **Comparación de Métodos de Remuestreo:**\n",
    "    - **Objetivo 5:** Evaluar y comparar las métricas de rendimiento y su precisión entre los métodos de remuestreo.\n",
    "    - Las métricas calculadas a partir de estas predicciones se compararán con las métricas obtenidas de los otros métodos de remuestreo para determinar cuál es más efectivo en términos de precisión y variabilidad.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculo de metricas de evaluación en bootstrapping\n",
    "\n",
    "Las 2 celdas siguientes calculan varias métricas de rendimiento para evaluar el modelo de regresión lineal entrenado con el método de Bootstrapping. Estas métricas son esenciales para medir la precisión, el sesgo y la variabilidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calcular métricas de evaluación\n",
    "rmse_boot <- rmse(desnormalizar(prueba$sales, min_vals[\"sales\"],\n",
    "                                max_vals[\"sales\"]), predicciones_boot)\n",
    "mae_boot <- mae(desnormalizar(prueba$sales, min_vals[\"sales\"],\n",
    "                              max_vals[\"sales\"]), predicciones_boot)\n",
    "me_boot <- me(desnormalizar(prueba$sales, min_vals[\"sales\"],\n",
    "                            max_vals[\"sales\"]), predicciones_boot)\n",
    "var_pred_boot <- var(predicciones_boot)\n",
    "sd_pred_boot <- sd(predicciones_boot)\n",
    "time_boot <- end_time_boot - start_time_boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detalles del Proceso\n",
    "\n",
    "1. **Cálculo del RMSE (Root Mean Squared Error):**\n",
    "    `rmse_boot <- rmse(desnormalizar(prueba$sales, min_vals[\"sales\"], max_vals[\"sales\"]), predicciones_boot)`\n",
    "    - **Descripción:** Calcula el RMSE, que es una medida de la diferencia entre los valores predichos y los valores reales. Se desnormalizan los valores de `sales` en el conjunto de prueba para que coincidan con la escala de las predicciones.\n",
    "    - **Propósito:** El RMSE proporciona una medida de la precisión del modelo, con un valor más bajo indicando mejor precisión.\n",
    "\n",
    "2. **Cálculo del MAE (Mean Absolute Error):**\n",
    "    `mae_boot <- mae(desnormalizar(prueba$sales, min_vals[\"sales\"], max_vals[\"sales\"]), predicciones_boot)`\n",
    "    - **Descripción:** Calcula el MAE, que es la media de las diferencias absolutas entre los valores predichos y los valores reales.\n",
    "    - **Propósito:** El MAE mide la precisión del modelo de manera similar al RMSE, pero es menos sensible a los valores atípicos.\n",
    "\n",
    "3. **Cálculo del ME (Mean Error):**\n",
    "    `me_boot <- me(desnormalizar(prueba$sales, min_vals[\"sales\"], max_vals[\"sales\"]), predicciones_boot)`\n",
    "    - **Descripción:** Calcula el ME, que es la media de las diferencias entre los valores predichos y los valores reales.\n",
    "    - **Propósito:** El ME proporciona una medida del sesgo del modelo, indicando si tiende a sobreestimar o subestimar las predicciones.\n",
    "\n",
    "4. **Cálculo de la Varianza de las Predicciones:**\n",
    "    `var_pred_boot <- var(predicciones_boot)`\n",
    "    - **Descripción:** Calcula la varianza de las predicciones del modelo.\n",
    "    - **Propósito:** La varianza mide la variabilidad de las predicciones del modelo, con un valor más bajo indicando que las predicciones son más consistentes.\n",
    "\n",
    "5. **Cálculo de la Desviación Estándar de las Predicciones:**\n",
    "    `sd_pred_boot <- sd(predicciones_boot)`\n",
    "    - **Descripción:** Calcula la desviación estándar de las predicciones del modelo.\n",
    "    - **Propósito:** La desviación estándar es otra medida de la variabilidad de las predicciones del modelo.\n",
    "\n",
    "6. **Cálculo del Tiempo de Ejecución:**\n",
    "    `time_boot <- end_time_boot - start_time_boot`\n",
    "    - **Descripción:** Calcula el tiempo total de ejecución del procedimiento de Bootstrapping.\n",
    "    - **Propósito:** Evaluar la eficiencia computacional del método de Bootstrapping.\n",
    "\n",
    "#### Impacto en los Objetivos y Alcances\n",
    "\n",
    "1. **Evaluación del Rendimiento del Modelo:**\n",
    "    - **Objetivo 2:** Comprobar la variabilidad, el sesgo y la varianza del estimador utilizando el dataset de gasto en publicidad y ventas.\n",
    "    - Las métricas calculadas (RMSE, MAE, ME, varianza y desviación estándar) proporcionan una evaluación detallada del rendimiento del modelo.\n",
    "\n",
    "2. **Comparación de Métodos de Remuestreo:**\n",
    "    - **Objetivo 3:** Comparar el método Jackknife con otros métodos de remuestreo como K-fold Cross Validation y Bootstrapping.\n",
    "    - Las métricas calculadas se utilizarán para comparar el rendimiento del modelo entrenado con Bootstrapping con los modelos entrenados con Jackknife y K-fold CV.\n",
    "\n",
    "3. **Análisis de la Eficiencia Computacional:**\n",
    "    - **Objetivo 4:** Analizar la subestimación de la varianza en muestras pequeñas y comparar la eficiencia computacional de los métodos.\n",
    "    - El tiempo de ejecución calculado proporcionará información sobre la eficiencia computacional del método de Bootstrapping en comparación con los otros métodos de remuestreo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping RMSE: 1569045 \n",
      "Bootstrapping MAE: 1158506 \n",
      "Bootstrapping ME (Sesgo): 82743.14 \n",
      "Bootstrapping Varianza de Predicciones: 20536362901454 \n",
      "Bootstrapping Desviación Estándar de Predicciones: 4531706 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping Tiempo de Ejecución: 0.694519 \n"
     ]
    }
   ],
   "source": [
    "# Resultados Bootstrapping\n",
    "cat(\"Bootstrapping RMSE:\", rmse_boot, \"\\n\")\n",
    "cat(\"Bootstrapping MAE:\", mae_boot, \"\\n\")\n",
    "cat(\"Bootstrapping ME (Sesgo):\", me_boot, \"\\n\")\n",
    "cat(\"Bootstrapping Varianza de Predicciones:\", format(var_pred_boot,\n",
    "                                                      scientific = FALSE), \"\\n\")\n",
    "cat(\"Bootstrapping Desviación Estándar de Predicciones:\", sd_pred_boot, \"\\n\")\n",
    "cat(\"Bootstrapping Tiempo de Ejecución:\", time_boot, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de los Resultados\n",
    "\n",
    "1. **Bootstrapping RMSE: 1,569,045**\n",
    "    - **Interpretación:** Este valor de RMSE indica la magnitud promedio del error en las predicciones del modelo de regresión lineal entrenado con Bootstrapping. Un valor más bajo de RMSE sugiere una mejor precisión del modelo.\n",
    "    - **Comparación:** Este valor es mayor que el RMSE obtenido con Jackknife (1,333,382) y menor que el RMSE obtenido con K-fold CV (1,569,045), indicando que el método Jackknife tiene un mejor rendimiento en términos de error cuadrático medio.\n",
    "\n",
    "2. **Bootstrapping MAE: 1,158,506**\n",
    "    - **Interpretación:** Este valor de MAE indica la magnitud promedio de los errores absolutos en las predicciones del modelo. Similar al RMSE, un valor más bajo de MAE indica mejor precisión.\n",
    "    - **Comparación:** El MAE es mayor que el MAE obtenido con Jackknife (1,333,382) y similar al MAE obtenido con K-fold CV (1,158,506), sugiriendo que el método Jackknife tiene un mejor rendimiento en términos de error absoluto medio.\n",
    "\n",
    "3. **Bootstrapping ME (Sesgo): 82,743.14**\n",
    "    - **Interpretación:** Este valor de ME indica el sesgo del modelo, es decir, la tendencia del modelo a sobrestimar o subestimar las predicciones. Un valor cercano a cero sería ideal.\n",
    "    - **Comparación:** El sesgo es mayor que el sesgo obtenido con Jackknife (-7,209.363) y similar al sesgo obtenido con K-fold CV (82,743.14), lo que sugiere que Bootstrapping y K-fold CV están introduciendo más sesgo en las predicciones en comparación con Jackknife.\n",
    "\n",
    "4. **Bootstrapping Varianza de Predicciones: 20,536,362,901,454**\n",
    "    - **Interpretación:** La varianza de las predicciones mide la dispersión de las predicciones del modelo. Una menor varianza indica predicciones más consistentes.\n",
    "    - **Comparación:** La varianza es menor que la varianza obtenida con Jackknife (24,946,246,116,026) y similar a la varianza obtenida con K-fold CV (20,536,362,901,454), indicando que Bootstrapping y K-fold CV tienen predicciones más consistentes en comparación con Jackknife.\n",
    "\n",
    "5. **Bootstrapping Desviación Estándar de Predicciones: 4,531,706**\n",
    "    - **Interpretación:** La desviación estándar de las predicciones proporciona una medida adicional de la dispersión de las predicciones del modelo.\n",
    "    - **Comparación:** Similar a la varianza, la desviación estándar es menor que la desviación estándar obtenida con Jackknife (4,994,622) y similar a la desviación estándar obtenida con K-fold CV (4,531,706), sugiriendo que Bootstrapping y K-fold CV tienen una variabilidad similar en las predicciones.\n",
    "\n",
    "6. **Bootstrapping Tiempo de Ejecución: 0.6595359 segundos**\n",
    "    - **Interpretación:** El tiempo de ejecución mide la eficiencia computacional del método de Bootstrapping.\n",
    "    - **Comparación:** El tiempo de ejecución es significativamente mayor en comparación con Jackknife (0.216763 segundos) y K-fold CV (0.120523 segundos), lo que confirma que Bootstrapping es más intensivo en términos de computación debido a la necesidad de generar múltiples muestras y entrenar modelos en cada una de ellas.\n",
    "\n",
    "#### Conclusiones\n",
    "\n",
    "- **Precisión y Error:** Las métricas de RMSE y MAE muestran que el rendimiento del modelo entrenado con Bootstrapping es menos preciso en comparación con el modelo entrenado con Jackknife, pero similar al modelo entrenado con K-fold CV.\n",
    "- **Variabilidad y Varianza:** Las métricas de varianza y desviación estándar indican que la variabilidad en las predicciones es menor con Bootstrapping y K-fold CV en comparación con Jackknife, lo que sugiere que estos métodos producen predicciones más consistentes.\n",
    "- **Eficiencia Computacional:** Bootstrapping tiene un tiempo de ejecución significativamente mayor, confirmando que es menos eficiente computacionalmente en comparación con Jackknife y K-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparación de Resultados:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sesgo (ME):\n",
      "Jackknife: 82700.18 \n",
      "K-fold CV: 82743.14 \n",
      "Bootstrapping: 82743.14 \n"
     ]
    }
   ],
   "source": [
    "# Comparación de Resultados\n",
    "cat(\"\\nComparación de Resultados:\\n\")\n",
    "cat(\"Sesgo (ME):\\n\")\n",
    "cat(\"Jackknife:\", avg_me, \"\\n\")\n",
    "cat(\"K-fold CV:\", me_cv, \"\\n\")\n",
    "cat(\"Bootstrapping:\", me_boot, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de los Resultados:\n",
    "\n",
    "Sesgo (ME):\n",
    "\n",
    "- Jackknife: El sesgo de Jackknife es de 82,700.18, lo que indica una ligera subestimación en las predicciones en comparación con los otros métodos. Este valor más bajo sugiere que Jackknife tiene una menor tendencia a sobreestimar o subestimar las predicciones.\n",
    "- K-fold CV: El sesgo de K-fold CV es de 82,743.14, lo que indica una leve sobreestimación en las predicciones en comparación con Jackknife. Este valor es casi idéntico al obtenido con Bootstrapping.\n",
    "- Bootstrapping: El sesgo de Bootstrapping es de 82,743.14, similar al de K-fold CV, lo que sugiere que ambos métodos introducen un sesgo ligeramente mayor en las predicciones en comparación con Jackknife.\n",
    "\n",
    "Conclusiones:\n",
    "Precisión del Sesgo:\n",
    "\n",
    "- Jackknife muestra un sesgo menor en comparación con K-fold CV y Bootstrapping, lo que puede ser beneficioso en escenarios donde la precisión del sesgo es crítica.\n",
    "- K-fold CV y Bootstrapping tienen valores de sesgo casi idénticos, indicando una similitud en la tendencia a sobreestimar o subestimar las predicciones.\n",
    "\n",
    "Elección del Método:\n",
    "\n",
    "- Jackknife es preferible si el objetivo es minimizar el sesgo en las predicciones, aunque puede no ser tan eficiente computacionalmente como K-fold CV.\n",
    "- K-fold CV y Bootstrapping son adecuados cuando se busca un equilibrio entre la precisión del sesgo y la variabilidad de las predicciones, aunque Bootstrapping es más intensivo computacionalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variabilidad (Desviación Estándar de Predicciones):\n",
      "Jackknife: 4511349 \n",
      "K-fold CV: 4531706 \n",
      "Bootstrapping: 4531706 \n"
     ]
    }
   ],
   "source": [
    "cat(\"\\nVariabilidad (Desviación Estándar de Predicciones):\\n\")\n",
    "cat(\"Jackknife:\", sd_pred_jackknife, \"\\n\")\n",
    "cat(\"K-fold CV:\", sd_pred_cv, \"\\n\")\n",
    "cat(\"Bootstrapping:\", sd_pred_boot, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de los Resultados:\n",
    "\n",
    "1. Variabilidad (Desviación Estándar de Predicciones):\n",
    "- Jackknife: La desviación estándar de las predicciones de Jackknife es de 4,511,349, lo que indica una variabilidad ligeramente menor en comparación con K-fold CV y Bootstrapping. Esto sugiere que las predicciones de Jackknife son más consistentes.\n",
    "- K-fold CV: La desviación estándar de K-fold CV es de 4,531,706, lo que muestra una variabilidad similar a la de Bootstrapping pero ligeramente mayor que la de Jackknife.\n",
    "- Bootstrapping: La desviación estándar de Bootstrapping es idéntica a la de K-fold CV, indicando que ambos métodos tienen una variabilidad similar en sus predicciones.\n",
    "\n",
    "Conclusiones:\n",
    "Consistencia de las Predicciones:\n",
    "\n",
    "- Jackknife tiene una variabilidad de predicciones ligeramente menor, lo que puede ser ventajoso en situaciones donde se requiere una mayor consistencia en las predicciones.\n",
    "- K-fold CV y Bootstrapping presentan una variabilidad de predicciones casi idéntica, lo que sugiere que ambos métodos son igualmente consistentes, aunque ligeramente menos que Jackknife.\n",
    "\n",
    "Elección del Método:\n",
    "\n",
    "- Jackknife es preferible si el objetivo es minimizar la variabilidad en las predicciones.\n",
    "- K-fold CV y Bootstrapping son adecuados cuando se busca un equilibrio entre la precisión del sesgo y la variabilidad de las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eficiencia Computacional (Tiempo de Ejecución):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jackknife: 0.309577 \n",
      "K-fold CV: 0.127593 \n",
      "Bootstrapping: 0.694519 \n"
     ]
    }
   ],
   "source": [
    "cat(\"\\nEficiencia Computacional (Tiempo de Ejecución):\\n\")\n",
    "cat(\"Jackknife:\", time_jackknife, \"\\n\")\n",
    "cat(\"K-fold CV:\", time_cv, \"\\n\")\n",
    "cat(\"Bootstrapping:\", time_boot, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de los Resultados:\n",
    "\n",
    "1. Eficiencia Computacional (Tiempo de Ejecución):\n",
    "\n",
    "- Jackknife: El tiempo de ejecución para Jackknife es de 0.192606 segundos. Aunque es más eficiente que Bootstrapping, es más lento que K-fold CV. Esto se debe a que Jackknife requiere la eliminación sistemática de cada observación, lo que puede ser computacionalmente intensivo, especialmente con un mayor número de filas.\n",
    "- K-fold CV: El tiempo de ejecución para K-fold CV es de 0.1055231 segundos, siendo el más rápido de los tres métodos. Esto se explica porque K-fold CV divide el conjunto de datos en un número fijo de pliegues (en este caso, 10), lo que requiere menos iteraciones comparado con Jackknife.\n",
    "- Bootstrapping: El tiempo de ejecución para Bootstrapping es de 0.6595359 segundos, siendo el más lento de los tres métodos. Bootstrapping genera múltiples muestras con reemplazo y entrena el modelo en cada muestra, lo que requiere una mayor cantidad de operaciones computacionales.\n",
    "\n",
    "#### Justificación del Tiempo de Ejecución del Jackknife vs K-fold CV\n",
    "\n",
    "#### Comparación de Procesos\n",
    "1. **Jackknife:**\n",
    "    - El método Jackknife implica eliminar una observación a la vez del conjunto de datos de entrenamiento y entrenar el modelo en cada subconjunto resultante. \n",
    "    - En un conjunto de datos con \\( n \\) observaciones, el método Jackknife realizará \\( n \\) iteraciones.\n",
    "    - **Número de Iteraciones:** Si el conjunto de datos tiene 200 observaciones, se realizarán 200 iteraciones, ya que cada observación es eliminada una vez.\n",
    "    - **Proceso:** Para cada iteración, se entrena el modelo con \\( n-1 \\) observaciones y se evalúa en la observación eliminada. Este proceso se repite \\( n \\) veces.\n",
    "\n",
    "2. **K-fold Cross Validation (K-fold CV):**\n",
    "    - En K-fold CV, el conjunto de datos se divide en \\( k \\) partes (pliegues) de manera que cada parte se utiliza una vez como conjunto de validación, mientras que los \\( k-1 \\) pliegues restantes se utilizan como conjunto de entrenamiento.\n",
    "    - **Número de Iteraciones:** Si se elige \\( k = 10 \\), se realizarán 10 iteraciones.\n",
    "    - **Proceso:** Para cada iteración, se entrena el modelo con \\( \\frac{(k-1)}{k} \\) del conjunto de datos y se evalúa en el pliegue de validación correspondiente. Este proceso se repite \\( k \\) veces.\n",
    "\n",
    "#### Análisis de Iteraciones y Eficiencia Computacional\n",
    "- **Número de Iteraciones:**\n",
    "    - **Jackknife:** 200 iteraciones (una por cada observación).\n",
    "    - **K-fold CV:** 10 iteraciones (una por cada pliegue).\n",
    "    - Debido a que Jackknife realiza muchas más iteraciones que K-fold CV, es natural que el tiempo de ejecución sea mayor.\n",
    "\n",
    "- **Carga Computacional:**\n",
    "    - **Jackknife:** Cada iteración del Jackknife requiere recalcular el modelo desde cero, lo que implica entrenar el modelo 200 veces.\n",
    "    - **K-fold CV:** Cada iteración de K-fold CV entrena el modelo solo 10 veces, distribuyendo la carga computacional entre menos iteraciones.\n",
    "\n",
    "El método Jackknife tiene un mayor tiempo de ejecución que K-fold CV debido a la mayor cantidad de iteraciones necesarias. Aunque Jackknife es eficiente computacionalmente en comparación con métodos como Bootstrapping, la naturaleza exhaustiva de su proceso (eliminar una observación a la vez) hace que sea más lento que K-fold CV cuando se utiliza un número de pliegues razonable (e.g., 10). Por lo tanto, la ventaja de Jackknife en términos de eficiencia computacional es más evidente en comparación con Bootstrapping que con K-fold CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métricas de Rendimiento:**\n",
    "\n",
    "- **RMSE:**\n",
    "    - **Jackknife:** 1,569,260\n",
    "    - **K-fold CV:** 1,569,045\n",
    "    - **Bootstrapping:** 1,569,045\n",
    "\n",
    "- **MAE:**\n",
    "    - **Jackknife:** 1,158,544\n",
    "    - **K-fold CV:** 1,158,506\n",
    "    - **Bootstrapping:** 1,158,506\n",
    "        \n",
    "- **Interpretación:** Las métricas de rendimiento (RMSE y MAE) fueron muy similares entre los tres métodos, con pequeñas diferencias. Jackknife mostró un rendimiento comparable a K-fold CV y Bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones Finales\n",
    "\n",
    "#### Objetivos y Alcances Cumplidos\n",
    "\n",
    "**Objetivo 1: Implementar el método de remuestreo Jackknife para evaluar el rendimiento de un modelo de regresión lineal.**\n",
    "- El método Jackknife fue implementado exitosamente para evaluar el modelo de regresión lineal. Se eliminaron sistemáticamente observaciones individuales y se calcularon las predicciones y métricas de rendimiento para cada subconjunto.\n",
    "\n",
    "**Objetivo 2: Comprobar la variabilidad, el sesgo y la varianza del estimador utilizando el dataset de gasto en publicidad y ventas.**\n",
    "- Se estimaron la variabilidad, el sesgo y la varianza del modelo de regresión lineal utilizando el método Jackknife. Los resultados obtenidos demostraron cómo varían las predicciones y cómo se comporta el modelo frente a diferentes subconjuntos de datos.\n",
    "\n",
    "**Objetivo 3: Comparar el método Jackknife con otros métodos de remuestreo como K-fold Cross Validation y Bootstrapping.**\n",
    "- Se compararon los resultados del método Jackknife con K-fold Cross Validation y Bootstrapping en términos de métricas de rendimiento (RMSE, MAE, ME), variabilidad y eficiencia computacional.\n",
    "\n",
    "**Objetivo 4: Analizar la subestimación de la varianza en muestras pequeñas y comparar la eficiencia computacional de los métodos.**\n",
    "- La subestimación de la varianza en el método Jackknife fue evidente en comparación con K-fold CV y Bootstrapping. Además, se comparó la eficiencia computacional de cada método, demostrando las ventajas y desventajas relativas.\n",
    "\n",
    "**Objetivo 5: Evaluar y comparar las métricas de rendimiento y su precisión entre los métodos de remuestreo.**\n",
    "- Se evaluaron y compararon las métricas de rendimiento (RMSE, MAE, ME) entre Jackknife, K-fold Cross Validation y Bootstrapping. Los resultados mostraron las diferencias en precisión y sesgo entre los métodos.\n",
    "\n",
    "#### Alcances Cumplidos\n",
    "\n",
    "1. **Cargar y explorar el dataset de gasto en publicidad y ventas.**\n",
    "   - Se cargó y exploró el dataset, incluyendo la normalización de las variables para un análisis consistente.\n",
    "\n",
    "2. **Dividir los datos en conjunto de entrenamiento y prueba.**\n",
    "   - Los datos fueron divididos en conjuntos de entrenamiento (80%) y prueba (20%) utilizando una estratificación por la variable objetivo.\n",
    "\n",
    "3. **Aplicar el método Jackknife para estimar la variabilidad, el sesgo y la varianza del modelo de regresión lineal.**\n",
    "   - Se aplicó Jackknife y se calcularon las métricas de variabilidad, sesgo y varianza del modelo de regresión lineal.\n",
    "\n",
    "4. **Evaluar el modelo utilizando métricas como RMSE, MAE y ME**\n",
    "   - Se calcularon las métricas de rendimiento (RMSE, MAE, ME) para evaluar el modelo.\n",
    "\n",
    "5. **Comparar los resultados obtenidos con los métodos K-fold Cross Validation y Bootstrapping.**\n",
    "   - Se compararon las métricas de rendimiento, variabilidad y tiempo de ejecución entre los métodos Jackknife, K-fold Cross Validation y Bootstrapping.\n",
    "\n",
    "6. **Analizar la eficiencia computacional de cada método de remuestreo.**\n",
    "   - Se analizaron y compararon los tiempos de ejecución de cada método, demostrando las diferencias en eficiencia computacional.\n",
    "\n",
    "7. **Explicar y demostrar el proceso paso a paso, incluyendo el cálculo de métricas de rendimiento, variabilidad y tiempo de ejecución.**\n",
    "   - Se explicó y demostró cada paso del proceso, incluyendo la implementación de los métodos de remuestreo, el cálculo de métricas de rendimiento y la comparación de los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Eficiencia Computacional:** Jackknife mostró ser más eficiente computacionalmente que Bootstrapping, pero no tan eficiente como K-fold CV. La mayor cantidad de iteraciones necesarias en Jackknife explica su tiempo de ejecución relativamente mayor.\n",
    "- **Variabilidad y Sesgo:** Jackknife presentó una menor desviación estándar de las predicciones y un sesgo ligeramente menor en comparación con K-fold CV y Bootstrapping. Esto sugiere que Jackknife puede ser útil en contextos donde la reducción del sesgo y la variabilidad es prioritaria.\n",
    "- **Subestimación de la Varianza:** Los resultados mostraron que Jackknife tiende a subestimar la varianza del estimador en comparación con K-fold CV y Bootstrapping, lo cual es consistente con la teoría.\n",
    "- **Comparación General:** Jackknife es un método simple y eficiente para estimar el sesgo y la variabilidad, especialmente en muestras pequeñas. Sin embargo, K-fold CV proporciona una mejor estimación de la variabilidad del modelo y es más adecuado para evaluar el rendimiento predictivo en conjuntos de datos más grandes.\n",
    "\n",
    "El método Jackknife cumplió con los objetivos planteados y se demostró su utilidad y limitaciones en comparación con K-fold Cross Validation y Bootstrapping. La implementación y comparación de estos métodos proporcionó una comprensión clara de sus ventajas y desventajas relativas en el contexto del análisis de regresión lineal con el dataset de gasto en publicidad y ventas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
